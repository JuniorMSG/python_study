"""
    subject
        Machine_Running
    topic
        ë§ˆì¼€íŒ… ë°ì´í„° ì‹¤ìŠµ

    Describe


        axes : https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html
        x = np.linspace(0, 2 * np.pi, 400)
        y = np.sin(x ** 2)
        ax_temp.scatter(x, y)

    Contens
        01.
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns




def marketing_01():
    """
        subject
            Machine_Running
        topic
            ex4. Kaggle_Data_Set : Advertising
        content
            01. ë°ì´í„° íƒìƒ‰
        Describe

            Kaggle Data_Set
                DATA
                TV      - TV ë§¤ì²´ë¹„
                Radio   - ë¼ë””ì˜¤ ë§¤ì²´ë¹„
                News    - ì‹ ë¬¸ ë§¤ì²´ë¹„
                sales   - ë§¤ì¶œì•¡

                ë¬¸ì œ ì •ì˜
                    ì „ì œ
                        ì‹¤ì œë¡œëŠ” ê´‘ê³  ë§¤ì²´ë¹„ ì´ì™¸ì˜ ë§ì€ ìš”ì¸ì´ ë§¤ì¶œì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤. (ì˜ì—…ì¸ë ¥ ìˆ˜ ,ì…ì†Œë¬¸, ê²½ê¸°, ìœ í–‰ ë“±..)
                        ë¶„ì„ì—ì„œëŠ” ë‹¤ë¥¸ ìš”ì¸ì´ ëª¨ë‘ ë™ì¼í•œ ìƒí™©ì—ì„œ ë§¤ì²´ë¹„ë§Œ ë³€ê²½í–ˆì„ ë•Œ ë§¤ì¶œì•¡ì˜ ë³€í™”ê°€ ë°œìƒí•œ ê²ƒì´ë¼ê³  ê°„ì£¼
                        ì‹¤ì œë¡œ Acquisition ë‹¨ê³„ì—ì„œëŠ” ì¢…ì†ë³€ìˆ˜ê°€ ë§¤ì¶œì•¡ë³´ë‹¤ëŠ” ë°©ë¬¸ììˆ˜, ê°€ì…ììˆ˜, DAU, MAUë“±ì˜ ì§€í‘œê°€ ë  ê²ƒ.
                        2011ë…„ ë°ì´í„°ì„
                    ë¶„ì„ì˜ ëª©ì 
                        ê° ë¯¸ë””ì–´ë³„ë¡œ ë§¤ì²´ë¹„ë¥¼ ì–´ë–»ê²Œ ì“°ëŠëƒì— ë”°ë¼ì„œ ë§¤ì¶œì•¡ì´ ì–´ë–»ê²Œ ë‹¬ë¼ì§ˆì§€ ì˜ˆì¸¡
                        ê¶ê·¹ì ìœ¼ë¡œëŠ” ë§¤ì¶œì•¡ì„ ìµœëŒ€í™” í•  ìˆ˜ ìˆëŠ” ë¯¸ë””ì–´ ë¯¹ìŠ¤ì˜ êµ¬ì„±ì„ ë„ì¶œ
                        ì´ ë¯¸ë””ì–´ë¯¹ìŠ¤ëŠ” í–¥í›„ ë¯¸ë””ì–´ í”Œëœì„ ìˆ˜ë¦½í•  ë•Œ ì‚¬ìš© ë  ìˆ˜ ìˆë‹¤.

        sub Contents
            01.
    """
    # DATA                  - ì¬ë£Œ
    # Processing Algorithm  - ì¡°ë¦¬ë²•  (Python, ê°•í™”í•™ìŠµ ë“±ë“±..)
    # Application           - ìš”ë¦¬    (ì•ŒíŒŒê³ , ì±—ë´‡, ì´ëŸ°ì €ëŸ° ì–´í”Œë¦¬ì¼€ì´ì…˜ ë“±ë“±)
    # AARRR & (RARRA ì¤‘ìš”ë„ì— ë”°ë¼ì„œ ì¡°ê¸ˆì”© ë‹¤ë¦„)

    # Acquisition(ì‚¬ìš©ìíšë“), Activation (ì‚¬ìš©ì í™œì„±í™”), Retention(ì‚¬ìš©ì ìœ ì§€), Revenue(ë§¤ì¶œ), Referral(ì¶”ì²œ)

    # Activation(ì‚¬ìš©ì í™œì„±í™”)   : ì‚¬ìš©ìê°€ ì–´ë–»ê²Œ ì„œë¹„ìŠ¤ë¥¼ ì ‘í•˜ëŠ”ê°€ ? ( DAU, MAU, New User, ë°©ë¬¸ì ìˆ˜ ë“±)
    # Acquisition(ì‚¬ìš©ìíšë“)    : ì‚¬ìš©ìê°€ ì²˜ìŒ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í–ˆì„ ë•Œ ê²½í—˜ì´ ì¢‹ì•˜ëŠ”ê°€?  ( Avg, PV, Avg. Duration, ê°€ì…ì ìˆ˜ ë“±)
    # Retention(ì‚¬ìš©ì ìœ ì§€) : ì‚¬ìš©ìê°€ ìš°ë¦¬ ì„œë¹„ìŠ¤ë¥¼ ê³„ì† ì´ìš©í•˜ëŠ”ê°€? ( Retention Rate )
    # Revenue(ë§¤ì¶œ) : ì–´ë–»ê²Œ ëˆì„ ë²„ëŠ”ê°€ ? ( Conversion )
    # Referral(ì¶”ì²œ) : ì‚¬ìš©ìê°€ ë‹¤ë¥¸ ì‚¬ëŒë“¤ì—ê²Œ ì œí’ˆì„ ì†Œê°œí•˜ëŠ”ê°€? (SNS Share Rate)

    # STEP 1. ë¯¸ë””ì–´ë³„ ê´‘ê³ ë¹„ EDA
    # STEP 2. ë¶„ì„ ëª¨ë¸ë§ ë§¤ì²´ë¹„ë¡œ ì„¸ì¼ì¦ˆ ì˜ˆì¸¡
    # STEP 3. ë¶„ì„ ê²°ê³¼ í•´ì„ ì ìš© ë°©ì•ˆ

    print("\n", "=" * 5, "01", "=" * 5)
    df = pd.read_csv("./data_file/Advertising.csv")
    """
        ê¸°ë³¸ ì²´í¬ ì‘ì—…
        1. ë°ì´í„° í™•ì¸   : df.shape, df.head(), df.tail()
        2. ê²°ì¸¡ê°’ ì¸¡ì •   : df.info(), df.isnull().sum()
        3. ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        4. ê¸°ìˆ í†µê³„ í™•ì¸ : df.describe()
        5. ë³€ìˆ˜ê°„ì˜ correlation í™•ì¸
        6. ë³€ìˆ˜ê°„ì˜ pairplot í™•ì¸
        7. Label, Feature(ì¸í’‹ ë³€ìˆ˜, ë…ë¦½ ë³€ìˆ˜) ì§€ì •
        
    """

    fig, axes = plt.subplots(2, 4, sharey=False, tight_layout=True, figsize=(15, 6), num='view')
    # fig = plt.figure(tight_layout=True, figsize=(15, 6), num='view')

    # ë°ì´í„° í™•ì¸
    print(df.shape)
    print(df.tail())
    # ê²°ì¸¡ê°’ ì¸¡ì •
    print(df.info())
    print(df.isnull().sum())

    # ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    df = df[['TV', 'radio', 'newspaper', 'sales']]

    # ê¸°ìˆ í†µê³„ í™•ì¸ : df.describe()
    print(df.describe())

    # ë³€ìˆ˜ê°„ì˜ correlation í™•ì¸ df.corr() ì‹œê°í™”
    corr = df.corr()
    print(corr)
    # annot=True ìˆ«ì í‘œì‹œí•´ì¤Œ

    ax_temp = axes[0, 0]
    ax_temp.set_title('HeatMap')
    sns.heatmap(corr, annot=True, ax=ax_temp)

    ax_temp = axes[0, 1]
    ax_temp.set_title('Scatter TV')
    sns.scatterplot(data=df, x='TV', y='sales', ax=ax_temp)

    ax_temp = axes[0, 2]
    ax_temp.set_title('Scatter Radio')
    sns.scatterplot(data=df, x='radio', y='sales', ax=ax_temp)

    ax_temp = axes[0, 3]
    ax_temp.set_title('Scatter News')
    sns.scatterplot(data=df, x='newspaper', y='sales', ax=ax_temp)




    # 6. ë³€ìˆ˜ê°„ì˜ pairplot ì¶œë ¥
    sns.pairplot(df[['TV', 'radio', 'newspaper', 'sales']])

    # 7. Label, Feature(ì¸í’‹ ë³€ìˆ˜, ë…ë¦½ ë³€ìˆ˜) ì§€ì •
    Labels = df['sales']
    features = df[['TV', 'radio', 'newspaper']]
    print(Labels.shape)
    print(features.shape)




    print("\n", "=" * 3, "01.", "=" * 3)

    # ì„ í˜•íšŒê·€ ë¶„ì„ (stats model)
    import statsmodels.formula.api as sm
    model1 = sm.ols(formula='sales ~ TV + radio + newspaper', data=df).fit()
    print(model1.summary())

    # ë¶„ì„ì´ ì˜ëœê²ƒì¸ê°€ ?
    # R-squared: 0.897 ë†’ì„ ìˆ˜ë¡ ì¢‹ì§€ë§Œ ë„ˆë¬´ ë†’ìœ¼ë©´ ë¬´ì–¸ê°€ ì˜ëª» ëœê²ƒ..
    # P>|t| (P-value) í†µê³„ì ìœ¼ë¡œ ì˜ë¯¸ê°€ ìˆëŠ” ê°’ì¸ê°€? (0.05 ì´ìƒì´ë©´ ìœ ì˜í•˜ì§€ ì•Šë‹¤.)
    # coef

    # ì„ í˜•íšŒê·€ ë¶„ì„ (sklearn model)
    from sklearn.datasets import make_regression
    from sklearn.linear_model import LinearRegression
    model2 = LinearRegression().fit(features, Labels)
    print(model2.intercept_ , model2.coef_)

    print("\n", "=" * 3, "02.", "=" * 3)

    model1 = sm.ols(formula='sales ~ TV + radio + newspaper', data=df).fit()
    model2 = sm.ols(formula='sales ~ TV + radio', data=df).fit()
    model3 = sm.ols(formula='sales ~ TV', data=df).fit()

    dict_data = {'TV' : 300, 'radio' : 10, 'newspaper' : 4}
    model1_pred = model1.predict({'TV' : 300, 'radio' : 10, 'newspaper' : 4})
    print(model1_pred)
    pred = 2.9389 + 0.0458 * dict_data['TV'] + 0.1885 * dict_data['radio'] - 0.0010 * dict_data['newspaper']
    print(pred)
    """
        Intercept      2.9389      0.312      9.422      0.000       2.324       3.554
        TV             0.0458      0.001     32.809      0.000       0.043       0.049
        radio          0.1885      0.009     21.893      0.000       0.172       0.206
        newspaper     -0.0010      0.006     -0.177      0.860      -0.013       0.011
    """

    print(model1.summary())
    print(model2.summary())
    print(model3.summary())

    # AIC, BICê°€ ê°€ì¥ ë‚®ì€ ëª¨ë¸ì´ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ë¡œ íŒë‹¨ í•  ìˆ˜ ìˆëŠ” ê¸°ì¤€ì´ ëœë‹¤.

    print("\n", "=" * 3, "03.", "=" * 3)

    # ë°ì´í„°ì˜ ì˜¤ë¥˜ë¥¼ ê²€ì¦í•´ë³´ì
    # ë¯¸ë””ì–´ë³„ ë§¤ì²´ë¹„ ë¶„í¬ë¥¼ seabornì˜ distplotìœ¼ë¡œ ì‹œê°í™”\

    ax_temp = axes[1, 0]
    ax_temp.set_title('dist TV')
    sns.distplot(df['TV'], ax=ax_temp)

    ax_temp = axes[1, 1]
    ax_temp.set_title('dist radio')
    sns.distplot(df['radio'], ax=ax_temp)

    ax_temp = axes[1, 2]
    ax_temp.set_title('dist newspaper')
    sns.distplot(df['newspaper'], ax=ax_temp)


    df['log_newspaper'] = np.log(df['newspaper'] + 1)
    ax_temp = axes[1, 3]
    ax_temp.set_title('dist log_newspaper')
    sns.distplot(df['log_newspaper'], ax=ax_temp)
    print(df[['log_newspaper', 'newspaper']])

    # newspaper ê°’ì´ ì¹˜ìš°ì³ì ¸ ìˆìœ¼ë‹ˆ ì •ê·œí™”ë¥¼ ìœ„í•´ ë¡œê·¸ ë³€í™˜
    # 0ì´ ë˜ë©´ ìŒì˜ ë¬´í•œëŒ€ê°’ì´ ë˜ê¸°ë•Œë¬¸ì— + ìˆ«ìë¥¼ í•´ì¤˜ì„œ ë°©ì§€í•˜ì—¬ ë¡œê·¸ë¡œ ë³€ê²½í•œë‹¤.

    model1 = sm.ols(formula='sales ~ TV + radio + newspaper', data=df).fit()
    # model2 = sm.ols(formula='sales ~ TV + radio', data=df).fit()
    # model3 = sm.ols(formula='sales ~ TV', data=df).fit()
    model4 = sm.ols(formula='sales ~ TV + radio + log_newspaper', data=df).fit()

    print(model1.summary())
    print(model4.summary())

    plt.show()


    # ì ìš© ë°©ì•ˆ


    print(df.shape)


# marketing_01()


def marketing_02():
    """
        subject
            Machine_Running
        topic
            ex4. marketing_data
        content
            02. Retention
        Describe
            í—ˆìƒì  ì§€í‘œ(Vanity Metric)
            í–‰ë™ì  ì§€í‘œ (Actionable Metric)

            OMTM - facebook,
            ì„œë¹„ìŠ¤ì— ë³¸ì§ˆì— ê°€ê¹Œìš´ ë¶„ì„ì´ í•„ìš”í•¨

            STEP 1. ëª¨ë°”ì¼ ê²Œì„ A/B Test ë°ì´í„°
            STEP 2. ë‘ ì§‘ë‹¨ì˜ A/B Test Retention ë¹„êµ
            STEP 3. ë¶„ì„ ê²°ê³¼ í•´ì„ ì ìš© ë°©ì•ˆ

        DATA_SET
            userid - ê°œë³„ ìœ ì €ë“¤ì„ êµ¬ë¶„í•˜ëŠ” ì‹ë³„ ë²ˆí˜¸
            version - ìœ ì €ë“¤ì´ ì‹¤í—˜êµ° ëŒ€ì¡°êµ° ì¤‘ ì†í•œ ìœ„ì¹˜
            sum_gamerounds - ì²« ì„¤ì¹˜ í›„ 14ì¼ ê°„ ìœ ì €ê°€ í”Œë ˆì´í•œ ë¼ìš´ë“œì˜ ìˆ˜
            retention_1 - ìœ ì €ê°€ ì„¤ì¹˜ í›„ 1ì¼ ì´ë‚´ì— ë‹¤ì‹œ ëŒì•„ì™”ëŠ”ì§€ ì—¬ë¶€
            retention_7 - ìœ ì €ê°€ ì„¤ì¹˜ í›„ 7ì¼ ì´ë‚´ì— ë‹¤ì‹œ ëŒì•„ì™”ëŠ”ì§€ ì—¬ë¶€

        ub Contents
            01.
    """

    print("\n", "=" * 5, "02", "=" * 5)
    df = pd.read_csv("./data_file/cookie_cats.csv")
    """
        ê¸°ë³¸ ì²´í¬ ì‘ì—…
        1. ë°ì´í„° í™•ì¸   : df.shape, df.head(), df.tail()
        2. ê²°ì¸¡ê°’ ì¸¡ì •   : df.info(), df.isnull().sum()
        3. ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        4. ê¸°ìˆ í†µê³„ í™•ì¸ : df.describe()
        5. ë³€ìˆ˜ê°„ì˜ correlation í™•ì¸
        6. ë³€ìˆ˜ê°„ì˜ pairplot í™•ì¸
        7. Label, Feature(ì¸í’‹ ë³€ìˆ˜, ë…ë¦½ ë³€ìˆ˜) ì§€ì •
    """

    fig, axes = plt.subplots(2, 4, sharey=False, tight_layout=True, figsize=(15, 6), num='mobile game')

    # ë°ì´í„° í™•ì¸
    print(df.shape)
    print(df.tail())
    # ê²°ì¸¡ê°’ ì¸¡ì •
    print(df.info())
    print(df.isnull().sum())

    # ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    df = df[['userid', 'version', 'sum_gamerounds', 'retention_1', 'retention_7']]

    # ê¸°ìˆ í†µê³„ í™•ì¸ : df.describe()
    print(df.describe())

    # ë³€ìˆ˜ê°„ì˜ correlation í™•ì¸ df.corr() ì‹œê°í™”
    corr = df.corr()
    print(corr)
    # annot=True ìˆ«ì í‘œì‹œí•´ì¤Œ

    ax_temp = axes[0, 0]
    ax_temp.set_title('HeatMap')
    sns.heatmap(corr, annot=True, ax=ax_temp)

    ax_temp = axes[0, 1]
    ax_temp.set_title('sum_gamerounds box plot')
    sns.boxenplot(data=df, y='sum_gamerounds', ax=ax_temp)

    # ì´ìƒí•œ ë°ì´í„° ì œê±°
    df[df['sum_gamerounds'] > 45000]
    df = df[df['sum_gamerounds'] < 45000]
    print(df['sum_gamerounds'].describe())

    ax_temp = axes[0, 2]
    ax_temp.set_title('sum_gamerounds box plot')
    sns.boxenplot(data=df, y='sum_gamerounds', ax=ax_temp)

    print("\n", "=" * 3, "01.", "=" * 3)
    # ë°ì´í„° ë¶„ì„ì‹œì‘.
    # ê·¸ë£¹ í™•ì¸.
    print(df.groupby('version').count())

    # ê²Œì„ íšŸìˆ˜ë³„ ìœ ì €ìˆ˜ í™•ì¸
    plot_df = df.groupby('sum_gamerounds')['userid'].count()
    print(plot_df)

    ax_temp = axes[0, 3]
    ax_temp.set_title('Line plot')
    ax_temp.set_ylabel('Number of Player')
    ax_temp.set_xlabel('# Game rounds')
    plot_df[:300].plot(figsize=(10, 6), ax=ax_temp)

    ax_temp = axes[1, 0]
    ax_temp.set_title('distplot')
    sns.distplot(df['sum_gamerounds'], ax=ax_temp)

    # ax_temp = axes[1, 1]
    # ax_temp.set_title('Scatter Radio')
    # sns.scatterplot(data=df, x='retention_1', ax=ax_temp)
    #
    # ax_temp = axes[1, 2]
    # ax_temp.set_title('Scatter News')
    # sns.scatterplot(data=df, x='retention_7', ax=ax_temp)

    # 6. ë³€ìˆ˜ê°„ì˜ pairplot ì¶œë ¥
    # sns.pairplot(df[['TV', 'radio', 'newspaper', 'sales']])
    #
    # 7. Label, Feature(ì¸í’‹ ë³€ìˆ˜, ë…ë¦½ ë³€ìˆ˜) ì§€ì •
    # Labels = df['sales']
    # features = df[['TV', 'radio', 'newspaper']]
    # print(Labels.shape)
    # print(features.shape)


    # 1-day retention ì •ë³´ ì¡°íšŒ
    # í‰ê· 
    print('', df['retention_1'].mean())
    print('retention_1 í‰ê· ', df['retention_1'].mean(), df.groupby('version')['retention_1'].mean())
    print('retention_7 í‰ê· ', df['retention_7'].mean(), df.groupby('version')['retention_7'].mean())

    # ë¶„ì„ ê²°ê³¼ í•´ì„ ì ìš© ë°©ì•ˆ
    # ì •ë§ ë°ì´í„°ê°„ì˜ ì°¨ì´ê°€ ìˆëŠ”ê²ƒì¼ê¹Œ?

    # Bootstrap ë°©ë²• .
    # T-test ë°©ë²• (ì—°ì†í˜• ìˆ«ìì¼ë•Œ ê°€ëŠ¥)
    # Chai Square ì •ë§ë¡œ ìœ ì˜ë¯¸í•˜ê²Œ ì°¨ì´ê°€ ìˆëŠ”ê²ƒì¸ê°€ ?

    boot_1d = []
    for i in range(1000):
        boot_mean = df.sample(frac=1, replace=True).groupby('version')['retention_1'].mean()
        boot_1d.append(boot_mean)

    # listë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    boot_1d = pd.DataFrame(boot_1d)

    # A Kernel Density Estimate plot of the bootstrap distributions
    boot_1d.plot(kind='density')
    plt.show()

    """
        ìœ„ì˜ ë‘ ë¶„í¬ëŠ” AB ë‘ ê·¸ë£¹ì— ëŒ€í•´ 1 day retentionì´ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ë¶€íŠ¸ ìŠ¤íŠ¸ë© ë¶ˆí™•ì‹¤ì„±ì„ í‘œí˜„í•©ë‹ˆë‹¤.
        ë¹„ë¡ ì‘ì§€ë§Œ ì°¨ì´ì˜ ì¦ê±°ê°€ìˆëŠ” ê²ƒ ê°™ì•„ ë³´ì…ë‹ˆë‹¤.
        ìì„¸íˆ ì‚´í´ë³´ê¸° ìœ„í•´ % ì°¨ì´ë¥¼ ê·¸ë ¤ ë´…ì‹œë‹¤.
    """

    # ë‘ AB ê·¸ë£¹ê°„ì˜ % ì°¨ì´ í‰ê·  ì»¬ëŸ¼ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    boot_1d['diff'] = (boot_1d.gate_30 - boot_1d.gate_40) / boot_1d.gate_40 * 100

    # bootstrap % ì°¨ì´ë¥¼ ì‹œê°í™” í•©ë‹ˆë‹¤.
    ax = boot_1d['diff'].plot(kind='density')
    ax.set_title('% difference in 1-day retention between the two AB-groups')

    # ê²Œì´íŠ¸ê°€ ë ˆë²¨30ì— ìˆì„ ë•Œ 1-day retentionì´ í´ í™•ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    print('ê²Œì´íŠ¸ê°€ ë ˆë²¨30ì— ìˆì„ ë•Œ 1-day retentionì´ í´ í™•ë¥ :', (boot_1d['diff'] > 0).mean())
    """
        ìœ„ ë„í‘œì—ì„œ ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ % ì°¨ì´ëŠ” ì•½ 1%-2%ì´ë©° ë¶„í¬ì˜ 95%ëŠ” 0% ì´ìƒì´ë©° ë ˆë²¨ 30ì˜ ê²Œì´íŠ¸ë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤.
        ë¶€íŠ¸ ìŠ¤íŠ¸ë© ë¶„ì„ì— ë”°ë¥´ë©´ ê²Œì´íŠ¸ê°€ ë ˆë²¨ 30ì—ìˆì„ ë•Œ 1ì¼ ìœ ì§€ìœ¨ì´ ë” ë†’ì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
        ê·¸ëŸ¬ë‚˜ í”Œë ˆì´ì–´ëŠ” í•˜ë£¨ ë™ì•ˆ ë§Œ ê²Œì„ì„í–ˆê¸° ë•Œë¬¸ì— ëŒ€ë¶€ë¶„ì˜ í”Œë ˆì´ì–´ê°€ ì•„ì§ ë ˆë²¨ 30ì— ë‹¤ë‹¤ë¥´ì§€ ì•Šì•˜ì„ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.
        ì¦‰, ëŒ€ë¶€ë¶„ì˜ ìœ ì €ë“¤ì€ ê²Œì´íŠ¸ê°€ 30ì— ìˆëŠ”ì§€ ì—¬ë¶€ì— ë”°ë¼ retentionì´ ì˜í–¥ë°›ì§€ ì•Šì•˜ì„ ê²ƒì…ë‹ˆë‹¤.
        ì¼ì£¼ì¼ ë™ì•ˆ í”Œë ˆì´ í•œ í›„ì—ëŠ” ë” ë§ì€ í”Œë ˆì´ì–´ê°€ ë ˆë²¨ 30ê³¼ 40ì— ë„ë‹¬í•˜ê¸° ë•Œë¬¸ì— 7 ì¼ retentionë„ í™•ì¸í•´ì•¼í•©ë‹ˆë‹¤.
    """

    df.groupby('version')['retention_7'].sum() / df.groupby('version')['retention_7'].count()

    boot_7d = []
    for i in range(500):
        boot_mean = df.sample(frac=1, replace=True).groupby('version')['retention_7'].mean()
        boot_7d.append(boot_mean)

    # listë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    boot_7d = pd.DataFrame(boot_7d)

    # ë‘ AB ê·¸ë£¹ê°„ì˜ % ì°¨ì´ í‰ê·  ì»¬ëŸ¼ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    boot_7d['diff'] = (boot_7d.gate_30 - boot_7d.gate_40) / boot_7d.gate_40 * 100

    # bootstrap % ì°¨ì´ë¥¼ ì‹œê°í™” í•©ë‹ˆë‹¤.
    ax = boot_7d['diff'].plot(kind='density')
    ax.set_title('% difference in 7-day retention between the two AB-groups')

    # ê²Œì´íŠ¸ê°€ ë ˆë²¨30ì— ìˆì„ ë•Œ 7-day retentionì´ ë” í´ í™•ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    print('ê²Œì´íŠ¸ê°€ ë ˆë²¨30ì— ìˆì„ ë•Œ 7-day retentionì´ í´ í™•ë¥ :', (boot_7d['diff'] > 0).mean())

    plt.show()

    print("\n", "=" * 3, "02.", "=" * 3)
    # T-test í†µê³„ì ì¸ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•˜ëŠ” ë°©ë²•.
    """
        https://www.statisticshowto.com/probability-and-statistics/t-test/
        T Score
            t-scoreê°€ í¬ë©´ ë‘ ê·¸ë£¹ì´ ë‹¤ë¥´ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
            t-scoreê°€ ì‘ìœ¼ë©´ ë‘ ê·¸ë£¹ì´ ë¹„ìŠ·í•˜ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
        P-values
            p-valueëŠ” 5%ìˆ˜ì¤€ì—ì„œ 0.05ì…ë‹ˆë‹¤.
            p-valuesëŠ” ì‘ì€ ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì´ê²ƒì€ ë°ì´í„°ê°€ ìš°ì—°íˆ ë°œìƒí•œ ê²ƒì´ ì•„ë‹ˆë¼ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
            ì˜ˆë¥¼ ë“¤ì–´ p-valueê°€ 0.01 ì´ë¼ëŠ” ê²ƒì€ ê²°ê³¼ê°€ ìš°ì—°íˆ ë‚˜ì˜¬ í™•ë¥ ì´ 1%ì— ë¶ˆê³¼í•˜ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
            ëŒ€ë¶€ë¶„ì˜ ê²½ìš° 0.05 (5%) ìˆ˜ì¤€ì˜ p-valueë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ìŠµë‹ˆë‹¤. ì´ ê²½ìš° í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ë‹¤ê³  í•©ë‹ˆë‹¤.
            
        ìœ„ ë¶„ì„ê²°ê³¼ë¥¼ ë³´ë©´, ë‘ ê·¸ë£¹ì—ì„œ retention_1ì— ìˆì–´ì„œëŠ” ìœ ì˜í•˜ì§€ ì•Šê³ , retention_7ì—ì„œëŠ” ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        ë‹¤ì‹œë§í•´, retention_7ì´ gate30ì´ gate40 ë³´ë‹¤ ë†’ì€ ê²ƒì€ ìš°ì—°íˆ ë°œìƒí•œ ì¼ì´ ì•„ë‹™ë‹ˆë‹¤.
        ì¦‰, gateëŠ” 30ì— ìˆëŠ” ê²ƒì´ 40ì— ìˆëŠ” ê²ƒë³´ë‹¤ retention 7 ì°¨ì›ì—ì„œ ë” ì¢‹ì€ ì„ íƒì§€ ì…ë‹ˆë‹¤.
    """


    # ìˆ˜í•™ì  ê³„ì‚°ì„ í•´ì£¼ëŠ” íŒŒì´ì¬ íŒ¨í‚¤ì§€
    from scipy import stats

    df_30 = df[df['version'] == 'gate_30']
    df_40 = df[df['version'] == 'gate_40']

    # ë…ë¦½í‘œë³¸ T-ê²€ì • (2 Sample T-Test)
    tTestResult = stats.ttest_ind(df_30['retention_1'], df_40['retention_1'])
    tTestResultDiffVar = stats.ttest_ind(df_30['retention_1'], df_40['retention_1'], equal_var=False)

    print(tTestResult, tTestResultDiffVar)

    tTestResult = stats.ttest_ind(df_30['retention_7'], df_40['retention_7'])
    tTestResultDiffVar = stats.ttest_ind(df_30['retention_7'], df_40['retention_7'], equal_var=False)
    print(tTestResult, tTestResultDiffVar)

    print("\n", "=" * 3, "03.", "=" * 3)

    # chi-square
    """
        chi-square
        ì‚¬ì‹¤ t-testëŠ” retention ì—¬ë¶€ë¥¼ 0,1 ë¡œ ë‘ê³  ë¶„ì„í•œ ê²ƒì…ë‹ˆë‹¤.
        í•˜ì§€ë§Œ ì‹¤ì œë¡œ retention ì—¬ë¶€ëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ì…ë‹ˆë‹¤. ì´ ë°©ë²•ë³´ë‹¤ëŠ” chi-squareê²€ì •ì„ í•˜ëŠ” ê²ƒì´ ë” ì¢‹ì€ ë°©ë²•ì…ë‹ˆë‹¤.
        ì¹´ì´ì œê³±ê²€ì •ì€ ì–´ë–¤ ë²”ì£¼í˜• í™•ë¥ ë³€ìˆ˜ ğ‘‹ ê°€ ë‹¤ë¥¸ ë²”ì£¼í˜• í™•ë¥ ë³€ìˆ˜ ğ‘Œ ì™€ ë…ë¦½ì¸ì§€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§€ëŠ”ê°€ë¥¼ ê²€ì¦í•˜ëŠ”ë°ë„ ì‚¬ìš©ë©ë‹ˆë‹¤.
        ì¹´ì´ì œê³±ê²€ì •ì„ ë…ë¦½ì„ í™•ì¸í•˜ëŠ”ë° ì‚¬ìš©í•˜ë©´ ì¹´ì´ì œê³± ë…ë¦½ê²€ì •ì´ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.
        ë§Œì•½ ë‘ í™•ë¥ ë³€ìˆ˜ê°€ ë…ë¦½ì´ë¼ë©´ ğ‘‹=0 ì¼ ë•Œì˜ ğ‘Œ ë¶„í¬ì™€ ğ‘‹=1 ì¼ ë•Œì˜ ğ‘Œ ë¶„í¬ê°€ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤.
        ë‹¤ì‹œë§í•´ ë²„ì „ì´ 30ì¼ë•Œì™€ 40ì¼ ë•Œ ëª¨ë‘ Yì˜ ë¶„í¬ê°€ ê°™ì€ ê²ƒì…ë‹ˆë‹¤.
        ë”°ë¼ì„œ í‘œë³¸ ì§‘í•©ì´ ê°™ì€ í™•ë¥ ë¶„í¬ì—ì„œ ë‚˜ì™”ë‹¤ëŠ” ê²ƒì„ ê·€ë¬´ê°€ì„¤ë¡œ í•˜ëŠ” ì¹´ì´ì œê³±ê²€ì •ì„ í•˜ì—¬ ì±„íƒëœë‹¤ë©´ ë‘ í™•ë¥ ë³€ìˆ˜ëŠ” ë…ë¦½ì…ë‹ˆë‹¤.
        ë§Œì•½ ê¸°ê°ëœë‹¤ë©´ ë‘ í™•ë¥ ë³€ìˆ˜ëŠ” ìƒê´€ê´€ê³„ê°€ ìˆëŠ” ê²ƒì…ë‹ˆë‹¤.
        ë‹¤ì‹œë§í•´ ì¹´ì´ì œê³±ê²€ì • ê²°ê³¼ê°€ ê¸°ê°ëœë‹¤ë©´ ê²Œì´íŠ¸ê°€ 30ì¸ì§€ 40ì¸ì§€ ì—¬ë¶€ì— ë”°ë¼ retentionì˜ ê°’ì´ ë³€í™”í•˜ê²Œ ëœë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.
        ğ‘‹ ì˜ ê°’ì— ë”°ë¥¸ ê°ê°ì˜ ğ‘Œ ë¶„í¬ê°€ 2ì°¨ì› í‘œ(contingency table)ì˜ í˜•íƒœë¡œ ì£¼ì–´ì§€ë©´ ë…ë¦½ì¸ ê²½ìš°ì˜ ë¶„í¬ì™€ ì‹¤ì œ y í‘œë³¸ë³¸í¬ì˜ ì°¨ì´ë¥¼ ê²€ì •í†µê³„ëŸ‰ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.
        ì´ ê°’ì´ ì¶©ë¶„íˆ í¬ë‹¤ë©´ ğ‘‹ ì™€ ğ‘Œ ëŠ” ìƒê´€ê´€ê³„ê°€ ìˆë‹¤.
    """
    # ë¶„í• í‘œë¥¼ ë§Œë“¤ê¸° ìœ„í•´ ë²„ì „ë³„ë¡œ ìƒì¡´ìì˜ ìˆ˜ í•©ê³„ë¥¼ êµ¬í•©ë‹ˆë‹¤.
    df.groupby('version').sum()

    # ë²„ì „ë³„ ì „ì²´ ìœ ì €ì˜ ìˆ˜ë¥¼ êµ¬í•©ë‹ˆë‹¤.
    df.groupby('version').count()

    import scipy as sp
    gate_40_01_sum = df.groupby('version').sum()['retention_1']['gate_40']
    gate_30_01_sum = df.groupby('version').sum()['retention_1']['gate_30']
    gate_40_07_sum = df.groupby('version').sum()['retention_7']['gate_40']
    gate_30_07_sum = df.groupby('version').sum()['retention_7']['gate_30']

    gate_40_01_cnt = df.groupby('version').count()['retention_1']['gate_40']
    gate_30_01_cnt = df.groupby('version').count()['retention_1']['gate_30']
    gate_40_07_cnt = df.groupby('version').count()['retention_7']['gate_40']
    gate_30_07_cnt = df.groupby('version').count()['retention_7']['gate_30']


    obs1 = np.array([[gate_40_01_sum, (gate_40_01_cnt - gate_40_01_sum)], [gate_30_01_sum, (gate_30_01_cnt - gate_30_01_sum)]])
    sp.stats.chi2_contingency(obs1)

    obs2 = np.array([[gate_40_07_sum, (gate_40_07_cnt - gate_40_07_sum)], [gate_30_07_sum, (gate_30_07_cnt - gate_30_07_sum)]])
    sp.stats.chi2_contingency(obs2)

    """
        OBS-1
        P-valueê°€ ì¤‘ìš” (0.075)
        (3.1698355431707994,
         0.07500999897705699,
         1,
         array([[20252.35970417, 25236.64029583],
                [19900.64029583, 24798.35970417]]))
        OBS-2
        P-valueê°€ ì¤‘ìš” (0.001)
        (9.915275528905669,
         0.0016391259678654423,
         1,
         array([[ 8463.49203885, 37025.50796115],
                [ 8316.50796115, 36382.49203885]]))
        ì¹´ì´ì œê³± ë…ë¦½ê²€ì •ì˜ ìœ ì˜í™•ë¥ ì€ 0.1%ì…ë‹ˆë‹¤.
        ì¦‰ ğ‘‹ ì™€ ğ‘Œ ëŠ” ìƒê´€ê´€ê³„ê°€ ìˆë‹¤ê³  ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        ê²Œì´íŠ¸ê°€ 30ì— ìˆëŠ”ì§€ 40ì— ìˆëŠ”ì§€ ì—¬ë¶€ì— ë”°ë¼ 7ì¼ ë’¤ retentionì´ ìƒê´€ê´€ê³„ê°€ ìˆëŠ” ê²ƒì…ë‹ˆë‹¤.
        7ì¼ ë’¤ retention ìœ ì§€ë¥¼ ìœ„í•˜ì—¬ ê²Œì´íŠ¸ëŠ” 30ì— ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.
    """

    """
        Bootstrap 
        T-Test  : í¬ê³  ì‘ì€ê²ƒì— ì˜ë¯¸ê°€ ìˆëŠ” ë°ì´í„°ì¼ ê²½ìš° ..? 
        Chai Square ë°ì´í„°ê°€ True Falseë¡œ ë‚˜ì˜¬ë•Œ..
        
        ê²°ë¡ 
            gateëŠ” 30ì— ìœ ì§€í•´ì•¼í•©ë‹ˆë‹¤.
            
            ë” ìƒê°í•´ ë³¼ ê²ƒ
            ì‹¤ì œë¡œëŠ” retention ì´ì™¸ì— í•¨ê»˜ ê³ ë ¤í•´ì•¼ í•  ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ë“¤ì´ ìˆìŠµë‹ˆë‹¤.
            ì•±ë‚´ êµ¬ë§¤, ê²Œì„ í”Œë ˆì´ íšŸìˆ˜, ì¹œêµ¬ì´ˆëŒ€ë¡œ ì¸í•œ referrer ë“± ì…ë‹ˆë‹¤.
            ë³¸ ë°ì´í„°ì—ì„œëŠ” retentionë§Œ ì£¼ì–´ì ¸ ìˆê¸°ì— í•œ ê°€ì§€ë¥¼ ì£¼ì•ˆì ì„ ë‘ì–´ ë¶„ì„ í–ˆìŠµë‹ˆë‹¤.
            ì„œë¹„ìŠ¤ ìš´ì˜ì, ê¸°íšì ì°¨ì›ì—ì„œ ì •ë§ ì¤‘ìš”í•œ ë©”íŠ¸ë¦­ì„ ì •í•˜ê³  ê·¸ ê²ƒì„ ê¸°ì¤€ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ í‰ê°€í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
    """


# marketing_02()


def marketing_03():
    """
        subject
            Machine_Running
        topic
            ex4. marketing_data
        content
            03. Revenue ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë‚˜ëˆ ë³´ì
        Describe
            ë¶„ì„í•  ë°ì´í„° íŒŒì•…
            mall ë°ì´í„° EDA
                CustomerID - ê³ ê°ë“¤ì—ê²Œ ë°°ì •ëœ ìœ ë‹ˆí¬í•œ ê³ ê° ë²ˆí˜¸ ì…ë‹ˆë‹¤.
                Gender - ê³ ê°ì˜ ì„±ë³„ ì…ë‹ˆë‹¤.
                Age - ê³ ê°ì˜ ë‚˜ì´ ì…ë‹ˆë‹¤.
                Annual Income (k$) - ê³ ê°ì˜ ì—°ì†Œë“ ì…ë‹ˆë‹¤.
                Spending Score (1-100) - ê³ ê°ì˜ êµ¬ë§¤í–‰ìœ„ì™€ êµ¬ë§¤ íŠ¹ì„±ì„ ë°”íƒ•ìœ¼ë¡œ mallì—ì„œ í• ë‹¹í•œ ê³ ê°ì˜ ì§€ë¶ˆ ì ìˆ˜ ì…ë‹ˆë‹¤.

            ë¬¸ì œ ì •ì˜
                ì „ì œ
                    ì£¼ì–´ì§„ ë°ì´í„°ê°€ ì ì ˆ ì •í™•í•˜ê²Œ ìˆ˜ì§‘, ê³„ì‚°ëœ ê²ƒì¸ì§€ì— ëŒ€í•œ ê²€ì¦ë¶€í„° ì‹œì‘í•´ì•¼í•˜ì§€ë§Œ,
                    ì§€ê¸ˆì€ ì£¼ì–´ì§„ ë°ì´í„°ê°€ ì •í™•í•˜ë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
                    (ì˜ˆ: Spending ScoreëŠ” ì ì ˆí•˜ê²Œ ì‚°ì¶œëœ ê²ƒì´ë¼ í™•ì‹ í•˜ê³  ì‹œì‘í•©ë‹ˆë‹¤)
                    ì£¼ì–´ì§„ ë³€ìˆ˜ë“¤ì„ ê°€ì§€ê³  ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.
                    ê°€ì¥ ì ì ˆí•œ ìˆ˜ì˜ ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.
                ë¶„ì„ì˜ ëª©ì 
                    ê° ì„¸ê·¸ë¨¼íŠ¸ ë³„ íŠ¹ì„±ì„ ë„ì¶œí•©ë‹ˆë‹¤.
                    ê° ì„¸ê·¸ë¨¼íŠ¸ë³„ íŠ¹ì„±ì— ë§ëŠ” í™œìš©ë°©ì•ˆ, ì „ëµì„ ê³ ë¯¼í•´ë´…ë‹ˆë‹¤.
        sub Contents
            01.
    """

    df = pd.read_csv("./data_file/Mall_Customers.csv")
    fig, axes = plt.subplots(2, 4, sharey=False, tight_layout=True, figsize=(15, 6), num='mobile game')

    # ë°ì´í„° í™•ì¸
    print(df.shape)
    print(df.tail())
    # ê²°ì¸¡ê°’ ì¸¡ì •
    print(df.info())
    print(df.isnull().sum())

    # ê¸°ìˆ í†µê³„ í™•ì¸ : df.describe()
    print(df.describe())

    # ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    # df = df[['userid', 'version', 'sum_gamerounds', 'retention_1', 'retention_7']]

    # ë³€ìˆ˜ê°„ì˜ correlation í™•ì¸ df.corr() ì‹œê°í™”
    corr = df.corr()
    print(corr)

    ax_temp = axes[0, 0]
    ax_temp.set_title('HeatMap')
    sns.heatmap(corr, annot=True, ax=ax_temp)

    # ax_temp = axes[0, 1]
    # ax_temp.set_title('sum_gamerounds box plot')
    # sns.boxenplot(data=df, y='', ax=ax_temp)

    plt.show()



    print("\n", "=" * 5, "03", "=" * 5)
    print("\n", "=" * 3, "01.", "=" * 3)
    print("\n", "=" * 3, "02.", "=" * 3)
    print("\n", "=" * 3, "03.", "=" * 3)


marketing_03()

def marketing_temp():
    """
        subject
            Machine_Running
        topic
            ex4. marketing_data
        content
            temp
        Describe

        sub Contents
            01.
    """

    print("\n", "=" * 5, "temp", "=" * 5)
    print("\n", "=" * 3, "01.", "=" * 3)
    print("\n", "=" * 3, "02.", "=" * 3)
    print("\n", "=" * 3, "03.", "=" * 3)

# marketing_temp()

