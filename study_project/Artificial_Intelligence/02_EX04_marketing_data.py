"""
    subject
        Machine_Running
    topic
        ë§ˆì¼€íŒ… ë°ì´í„° ì‹¤ìŠµ

    Describe


        axes : https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html
        x = np.linspace(0, 2 * np.pi, 400)
        y = np.sin(x ** 2)
        ax_temp.scatter(x, y)

    Contens
        01.
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns




def marketing_01():
    """
        subject
            Machine_Running
        topic
            ex4. Kaggle_Data_Set : Advertising
        content
            01. ë°ì´í„° íƒìƒ‰
        Describe

            Kaggle Data_Set
                DATA
                TV      - TV ë§¤ì²´ë¹„
                Radio   - ë¼ë””ì˜¤ ë§¤ì²´ë¹„
                News    - ì‹ ë¬¸ ë§¤ì²´ë¹„
                sales   - ë§¤ì¶œì•¡

                ë¬¸ì œ ì •ì˜
                    ì „ì œ
                        ì‹¤ì œë¡œëŠ” ê´‘ê³  ë§¤ì²´ë¹„ ì´ì™¸ì˜ ë§ì€ ìš”ì¸ì´ ë§¤ì¶œì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤. (ì˜ì—…ì¸ë ¥ ìˆ˜ ,ì…ì†Œë¬¸, ê²½ê¸°, ìœ í–‰ ë“±..)
                        ë¶„ì„ì—ì„œëŠ” ë‹¤ë¥¸ ìš”ì¸ì´ ëª¨ë‘ ë™ì¼í•œ ìƒí™©ì—ì„œ ë§¤ì²´ë¹„ë§Œ ë³€ê²½í–ˆì„ ë•Œ ë§¤ì¶œì•¡ì˜ ë³€í™”ê°€ ë°œìƒí•œ ê²ƒì´ë¼ê³  ê°„ì£¼
                        ì‹¤ì œë¡œ Acquisition ë‹¨ê³„ì—ì„œëŠ” ì¢…ì†ë³€ìˆ˜ê°€ ë§¤ì¶œì•¡ë³´ë‹¤ëŠ” ë°©ë¬¸ììˆ˜, ê°€ì…ììˆ˜, DAU, MAUë“±ì˜ ì§€í‘œê°€ ë  ê²ƒ.
                        2011ë…„ ë°ì´í„°ì„
                    ë¶„ì„ì˜ ëª©ì 
                        ê° ë¯¸ë””ì–´ë³„ë¡œ ë§¤ì²´ë¹„ë¥¼ ì–´ë–»ê²Œ ì“°ëŠëƒì— ë”°ë¼ì„œ ë§¤ì¶œì•¡ì´ ì–´ë–»ê²Œ ë‹¬ë¼ì§ˆì§€ ì˜ˆì¸¡
                        ê¶ê·¹ì ìœ¼ë¡œëŠ” ë§¤ì¶œì•¡ì„ ìµœëŒ€í™” í•  ìˆ˜ ìˆëŠ” ë¯¸ë””ì–´ ë¯¹ìŠ¤ì˜ êµ¬ì„±ì„ ë„ì¶œ
                        ì´ ë¯¸ë””ì–´ë¯¹ìŠ¤ëŠ” í–¥í›„ ë¯¸ë””ì–´ í”Œëœì„ ìˆ˜ë¦½í•  ë•Œ ì‚¬ìš© ë  ìˆ˜ ìˆë‹¤.

        sub Contents
            01.
    """
    # DATA                  - ì¬ë£Œ
    # Processing Algorithm  - ì¡°ë¦¬ë²•  (Python, ê°•í™”í•™ìŠµ ë“±ë“±..)
    # Application           - ìš”ë¦¬    (ì•ŒíŒŒê³ , ì±—ë´‡, ì´ëŸ°ì €ëŸ° ì–´í”Œë¦¬ì¼€ì´ì…˜ ë“±ë“±)
    # AARRR & (RARRA ì¤‘ìš”ë„ì— ë”°ë¼ì„œ ì¡°ê¸ˆì”© ë‹¤ë¦„)

    # Acquisition(ì‚¬ìš©ìíšë“), Activation (ì‚¬ìš©ì í™œì„±í™”), Retention(ì‚¬ìš©ì ìœ ì§€), Revenue(ë§¤ì¶œ), Referral(ì¶”ì²œ)

    # Activation(ì‚¬ìš©ì í™œì„±í™”)   : ì‚¬ìš©ìê°€ ì–´ë–»ê²Œ ì„œë¹„ìŠ¤ë¥¼ ì ‘í•˜ëŠ”ê°€ ? ( DAU, MAU, New User, ë°©ë¬¸ì ìˆ˜ ë“±)
    # Acquisition(ì‚¬ìš©ìíšë“)    : ì‚¬ìš©ìê°€ ì²˜ìŒ ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í–ˆì„ ë•Œ ê²½í—˜ì´ ì¢‹ì•˜ëŠ”ê°€?  ( Avg, PV, Avg. Duration, ê°€ì…ì ìˆ˜ ë“±)
    # Retention(ì‚¬ìš©ì ìœ ì§€) : ì‚¬ìš©ìê°€ ìš°ë¦¬ ì„œë¹„ìŠ¤ë¥¼ ê³„ì† ì´ìš©í•˜ëŠ”ê°€? ( Retention Rate )
    # Revenue(ë§¤ì¶œ) : ì–´ë–»ê²Œ ëˆì„ ë²„ëŠ”ê°€ ? ( Conversion )
    # Referral(ì¶”ì²œ) : ì‚¬ìš©ìê°€ ë‹¤ë¥¸ ì‚¬ëŒë“¤ì—ê²Œ ì œí’ˆì„ ì†Œê°œí•˜ëŠ”ê°€? (SNS Share Rate)

    # STEP 1. ë¯¸ë””ì–´ë³„ ê´‘ê³ ë¹„ EDA
    # STEP 2. ë¶„ì„ ëª¨ë¸ë§ ë§¤ì²´ë¹„ë¡œ ì„¸ì¼ì¦ˆ ì˜ˆì¸¡
    # STEP 3. ë¶„ì„ ê²°ê³¼ í•´ì„ ì ìš© ë°©ì•ˆ

    print("\n", "=" * 5, "01", "=" * 5)
    df = pd.read_csv("./data_file/Advertising.csv")
    """
        ê¸°ë³¸ ì²´í¬ ì‘ì—…
        1. ë°ì´í„° í™•ì¸   : df.shape, df.head(), df.tail()
        2. ê²°ì¸¡ê°’ ì¸¡ì •   : df.info(), df.isnull().sum()
        3. ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        4. ê¸°ìˆ í†µê³„ í™•ì¸ : df.describe()
        5. ë³€ìˆ˜ê°„ì˜ correlation í™•ì¸
        6. ë³€ìˆ˜ê°„ì˜ pairplot í™•ì¸
        7. Label, Feature(ì¸í’‹ ë³€ìˆ˜, ë…ë¦½ ë³€ìˆ˜) ì§€ì •
        
    """

    fig, axes = plt.subplots(2, 4, sharey=False, tight_layout=True, figsize=(15, 6), num='view')
    # fig = plt.figure(tight_layout=True, figsize=(15, 6), num='view')

    # ë°ì´í„° í™•ì¸
    print(df.shape)
    print(df.tail())
    # ê²°ì¸¡ê°’ ì¸¡ì •
    print(df.info())
    print(df.isnull().sum())

    # ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    df = df[['TV', 'radio', 'newspaper', 'sales']]

    # ê¸°ìˆ í†µê³„ í™•ì¸ : df.describe()
    print(df.describe())

    # ë³€ìˆ˜ê°„ì˜ correlation í™•ì¸ df.corr() ì‹œê°í™”
    corr = df.corr()
    print(corr)
    # annot=True ìˆ«ì í‘œì‹œí•´ì¤Œ

    ax_temp = axes[0, 0]
    ax_temp.set_title('HeatMap')
    sns.heatmap(corr, annot=True, ax=ax_temp)

    ax_temp = axes[0, 1]
    ax_temp.set_title('Scatter TV')
    sns.scatterplot(data=df, x='TV', y='sales', ax=ax_temp)

    ax_temp = axes[0, 2]
    ax_temp.set_title('Scatter Radio')
    sns.scatterplot(data=df, x='radio', y='sales', ax=ax_temp)

    ax_temp = axes[0, 3]
    ax_temp.set_title('Scatter News')
    sns.scatterplot(data=df, x='newspaper', y='sales', ax=ax_temp)




    # 6. ë³€ìˆ˜ê°„ì˜ pairplot ì¶œë ¥
    sns.pairplot(df[['TV', 'radio', 'newspaper', 'sales']])

    # 7. Label, Feature(ì¸í’‹ ë³€ìˆ˜, ë…ë¦½ ë³€ìˆ˜) ì§€ì •
    Labels = df['sales']
    features = df[['TV', 'radio', 'newspaper']]
    print(Labels.shape)
    print(features.shape)




    print("\n", "=" * 3, "01.", "=" * 3)

    # ì„ í˜•íšŒê·€ ë¶„ì„ (stats model)
    import statsmodels.formula.api as sm
    model1 = sm.ols(formula='sales ~ TV + radio + newspaper', data=df).fit()
    print(model1.summary())

    # ë¶„ì„ì´ ì˜ëœê²ƒì¸ê°€ ?
    # R-squared: 0.897 ë†’ì„ ìˆ˜ë¡ ì¢‹ì§€ë§Œ ë„ˆë¬´ ë†’ìœ¼ë©´ ë¬´ì–¸ê°€ ì˜ëª» ëœê²ƒ..
    # P>|t| (P-value) í†µê³„ì ìœ¼ë¡œ ì˜ë¯¸ê°€ ìˆëŠ” ê°’ì¸ê°€? (0.05 ì´ìƒì´ë©´ ìœ ì˜í•˜ì§€ ì•Šë‹¤.)
    # coef

    # ì„ í˜•íšŒê·€ ë¶„ì„ (sklearn model)
    from sklearn.datasets import make_regression
    from sklearn.linear_model import LinearRegression
    model2 = LinearRegression().fit(features, Labels)
    print(model2.intercept_ , model2.coef_)

    print("\n", "=" * 3, "02.", "=" * 3)

    model1 = sm.ols(formula='sales ~ TV + radio + newspaper', data=df).fit()
    model2 = sm.ols(formula='sales ~ TV + radio', data=df).fit()
    model3 = sm.ols(formula='sales ~ TV', data=df).fit()

    dict_data = {'TV' : 300, 'radio' : 10, 'newspaper' : 4}
    model1_pred = model1.predict({'TV' : 300, 'radio' : 10, 'newspaper' : 4})
    print(model1_pred)
    pred = 2.9389 + 0.0458 * dict_data['TV'] + 0.1885 * dict_data['radio'] - 0.0010 * dict_data['newspaper']
    print(pred)
    """
        Intercept      2.9389      0.312      9.422      0.000       2.324       3.554
        TV             0.0458      0.001     32.809      0.000       0.043       0.049
        radio          0.1885      0.009     21.893      0.000       0.172       0.206
        newspaper     -0.0010      0.006     -0.177      0.860      -0.013       0.011
    """

    print(model1.summary())
    print(model2.summary())
    print(model3.summary())

    # AIC, BICê°€ ê°€ì¥ ë‚®ì€ ëª¨ë¸ì´ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ë¡œ íŒë‹¨ í•  ìˆ˜ ìˆëŠ” ê¸°ì¤€ì´ ëœë‹¤.

    print("\n", "=" * 3, "03.", "=" * 3)

    # ë°ì´í„°ì˜ ì˜¤ë¥˜ë¥¼ ê²€ì¦í•´ë³´ì
    # ë¯¸ë””ì–´ë³„ ë§¤ì²´ë¹„ ë¶„í¬ë¥¼ seabornì˜ distplotìœ¼ë¡œ ì‹œê°í™”\

    ax_temp = axes[1, 0]
    ax_temp.set_title('dist TV')
    sns.distplot(df['TV'], ax=ax_temp)

    ax_temp = axes[1, 1]
    ax_temp.set_title('dist radio')
    sns.distplot(df['radio'], ax=ax_temp)

    ax_temp = axes[1, 2]
    ax_temp.set_title('dist newspaper')
    sns.distplot(df['newspaper'], ax=ax_temp)


    df['log_newspaper'] = np.log(df['newspaper'] + 1)
    ax_temp = axes[1, 3]
    ax_temp.set_title('dist log_newspaper')
    sns.distplot(df['log_newspaper'], ax=ax_temp)
    print(df[['log_newspaper', 'newspaper']])

    # newspaper ê°’ì´ ì¹˜ìš°ì³ì ¸ ìˆìœ¼ë‹ˆ ì •ê·œí™”ë¥¼ ìœ„í•´ ë¡œê·¸ ë³€í™˜
    # 0ì´ ë˜ë©´ ìŒì˜ ë¬´í•œëŒ€ê°’ì´ ë˜ê¸°ë•Œë¬¸ì— + ìˆ«ìë¥¼ í•´ì¤˜ì„œ ë°©ì§€í•˜ì—¬ ë¡œê·¸ë¡œ ë³€ê²½í•œë‹¤.

    model1 = sm.ols(formula='sales ~ TV + radio + newspaper', data=df).fit()
    # model2 = sm.ols(formula='sales ~ TV + radio', data=df).fit()
    # model3 = sm.ols(formula='sales ~ TV', data=df).fit()
    model4 = sm.ols(formula='sales ~ TV + radio + log_newspaper', data=df).fit()

    print(model1.summary())
    print(model4.summary())

    plt.show()


    # ì ìš© ë°©ì•ˆ


    print(df.shape)


# marketing_01()


def marketing_02():
    """
        subject
            Machine_Running
        topic
            ex4. marketing_data
        content
            02. Retention
        Describe
            í—ˆìƒì  ì§€í‘œ(Vanity Metric)
            í–‰ë™ì  ì§€í‘œ (Actionable Metric)

            OMTM - facebook,
            ì„œë¹„ìŠ¤ì— ë³¸ì§ˆì— ê°€ê¹Œìš´ ë¶„ì„ì´ í•„ìš”í•¨

            STEP 1. ëª¨ë°”ì¼ ê²Œì„ A/B Test ë°ì´í„°
            STEP 2. ë‘ ì§‘ë‹¨ì˜ A/B Test Retention ë¹„êµ
            STEP 3. ë¶„ì„ ê²°ê³¼ í•´ì„ ì ìš© ë°©ì•ˆ

        DATA_SET
            userid - ê°œë³„ ìœ ì €ë“¤ì„ êµ¬ë¶„í•˜ëŠ” ì‹ë³„ ë²ˆí˜¸
            version - ìœ ì €ë“¤ì´ ì‹¤í—˜êµ° ëŒ€ì¡°êµ° ì¤‘ ì†í•œ ìœ„ì¹˜
            sum_gamerounds - ì²« ì„¤ì¹˜ í›„ 14ì¼ ê°„ ìœ ì €ê°€ í”Œë ˆì´í•œ ë¼ìš´ë“œì˜ ìˆ˜
            retention_1 - ìœ ì €ê°€ ì„¤ì¹˜ í›„ 1ì¼ ì´ë‚´ì— ë‹¤ì‹œ ëŒì•„ì™”ëŠ”ì§€ ì—¬ë¶€
            retention_7 - ìœ ì €ê°€ ì„¤ì¹˜ í›„ 7ì¼ ì´ë‚´ì— ë‹¤ì‹œ ëŒì•„ì™”ëŠ”ì§€ ì—¬ë¶€

        ub Contents
            01.
    """

    print("\n", "=" * 5, "02", "=" * 5)
    df = pd.read_csv("./data_file/cookie_cats.csv")
    """
        ê¸°ë³¸ ì²´í¬ ì‘ì—…
        1. ë°ì´í„° í™•ì¸   : df.shape, df.head(), df.tail()
        2. ê²°ì¸¡ê°’ ì¸¡ì •   : df.info(), df.isnull().sum()
        3. ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        4. ê¸°ìˆ í†µê³„ í™•ì¸ : df.describe()
        5. ë³€ìˆ˜ê°„ì˜ correlation í™•ì¸
        6. ë³€ìˆ˜ê°„ì˜ pairplot í™•ì¸
        7. Label, Feature(ì¸í’‹ ë³€ìˆ˜, ë…ë¦½ ë³€ìˆ˜) ì§€ì •
    """

    fig, axes = plt.subplots(2, 4, sharey=False, tight_layout=True, figsize=(15, 6), num='mobile game')

    # ë°ì´í„° í™•ì¸
    print(df.shape)
    print(df.tail())
    # ê²°ì¸¡ê°’ ì¸¡ì •
    print(df.info())
    print(df.isnull().sum())

    # ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    df = df[['userid', 'version', 'sum_gamerounds', 'retention_1', 'retention_7']]

    # ê¸°ìˆ í†µê³„ í™•ì¸ : df.describe()
    print(df.describe())

    # ë³€ìˆ˜ê°„ì˜ correlation í™•ì¸ df.corr() ì‹œê°í™”
    corr = df.corr()
    print(corr)
    # annot=True ìˆ«ì í‘œì‹œí•´ì¤Œ

    ax_temp = axes[0, 0]
    ax_temp.set_title('HeatMap')
    sns.heatmap(corr, annot=True, ax=ax_temp)

    ax_temp = axes[0, 1]
    ax_temp.set_title('sum_gamerounds box plot')
    sns.boxenplot(data=df, y='sum_gamerounds', ax=ax_temp)

    # ì´ìƒí•œ ë°ì´í„° ì œê±°
    df[df['sum_gamerounds'] > 45000]
    df = df[df['sum_gamerounds'] < 45000]
    print(df['sum_gamerounds'].describe())

    ax_temp = axes[0, 2]
    ax_temp.set_title('sum_gamerounds box plot')
    sns.boxenplot(data=df, y='sum_gamerounds', ax=ax_temp)

    print("\n", "=" * 3, "01.", "=" * 3)
    # ë°ì´í„° ë¶„ì„ì‹œì‘.
    # ê·¸ë£¹ í™•ì¸.
    print(df.groupby('version').count())

    # ê²Œì„ íšŸìˆ˜ë³„ ìœ ì €ìˆ˜ í™•ì¸
    plot_df = df.groupby('sum_gamerounds')['userid'].count()
    print(plot_df)

    ax_temp = axes[0, 3]
    ax_temp.set_title('Line plot')
    ax_temp.set_ylabel('Number of Player')
    ax_temp.set_xlabel('# Game rounds')
    plot_df[:300].plot(figsize=(10, 6), ax=ax_temp)

    ax_temp = axes[1, 0]
    ax_temp.set_title('distplot')
    sns.distplot(df['sum_gamerounds'], ax=ax_temp)

    # ax_temp = axes[1, 1]
    # ax_temp.set_title('Scatter Radio')
    # sns.scatterplot(data=df, x='retention_1', ax=ax_temp)
    #
    # ax_temp = axes[1, 2]
    # ax_temp.set_title('Scatter News')
    # sns.scatterplot(data=df, x='retention_7', ax=ax_temp)

    # 6. ë³€ìˆ˜ê°„ì˜ pairplot ì¶œë ¥
    # sns.pairplot(df[['TV', 'radio', 'newspaper', 'sales']])
    #
    # 7. Label, Feature(ì¸í’‹ ë³€ìˆ˜, ë…ë¦½ ë³€ìˆ˜) ì§€ì •
    # Labels = df['sales']
    # features = df[['TV', 'radio', 'newspaper']]
    # print(Labels.shape)
    # print(features.shape)


    # 1-day retention ì •ë³´ ì¡°íšŒ
    # í‰ê· 
    print('', df['retention_1'].mean())
    print('retention_1 í‰ê· ', df['retention_1'].mean(), df.groupby('version')['retention_1'].mean())
    print('retention_7 í‰ê· ', df['retention_7'].mean(), df.groupby('version')['retention_7'].mean())

    # ë¶„ì„ ê²°ê³¼ í•´ì„ ì ìš© ë°©ì•ˆ
    # ì •ë§ ë°ì´í„°ê°„ì˜ ì°¨ì´ê°€ ìˆëŠ”ê²ƒì¼ê¹Œ?

    # Bootstrap ë°©ë²• .
    # T-test ë°©ë²• (ì—°ì†í˜• ìˆ«ìì¼ë•Œ ê°€ëŠ¥)
    # Chai Square ì •ë§ë¡œ ìœ ì˜ë¯¸í•˜ê²Œ ì°¨ì´ê°€ ìˆëŠ”ê²ƒì¸ê°€ ?

    boot_1d = []
    for i in range(1000):
        boot_mean = df.sample(frac=1, replace=True).groupby('version')['retention_1'].mean()
        boot_1d.append(boot_mean)

    # listë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    boot_1d = pd.DataFrame(boot_1d)

    # A Kernel Density Estimate plot of the bootstrap distributions
    boot_1d.plot(kind='density')
    plt.show()

    """
        ìœ„ì˜ ë‘ ë¶„í¬ëŠ” AB ë‘ ê·¸ë£¹ì— ëŒ€í•´ 1 day retentionì´ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ë¶€íŠ¸ ìŠ¤íŠ¸ë© ë¶ˆí™•ì‹¤ì„±ì„ í‘œí˜„í•©ë‹ˆë‹¤.
        ë¹„ë¡ ì‘ì§€ë§Œ ì°¨ì´ì˜ ì¦ê±°ê°€ìˆëŠ” ê²ƒ ê°™ì•„ ë³´ì…ë‹ˆë‹¤.
        ìì„¸íˆ ì‚´í´ë³´ê¸° ìœ„í•´ % ì°¨ì´ë¥¼ ê·¸ë ¤ ë´…ì‹œë‹¤.
    """

    # ë‘ AB ê·¸ë£¹ê°„ì˜ % ì°¨ì´ í‰ê·  ì»¬ëŸ¼ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    boot_1d['diff'] = (boot_1d.gate_30 - boot_1d.gate_40) / boot_1d.gate_40 * 100

    # bootstrap % ì°¨ì´ë¥¼ ì‹œê°í™” í•©ë‹ˆë‹¤.
    ax = boot_1d['diff'].plot(kind='density')
    ax.set_title('% difference in 1-day retention between the two AB-groups')

    # ê²Œì´íŠ¸ê°€ ë ˆë²¨30ì— ìˆì„ ë•Œ 1-day retentionì´ í´ í™•ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    print('ê²Œì´íŠ¸ê°€ ë ˆë²¨30ì— ìˆì„ ë•Œ 1-day retentionì´ í´ í™•ë¥ :', (boot_1d['diff'] > 0).mean())
    """
        ìœ„ ë„í‘œì—ì„œ ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ % ì°¨ì´ëŠ” ì•½ 1%-2%ì´ë©° ë¶„í¬ì˜ 95%ëŠ” 0% ì´ìƒì´ë©° ë ˆë²¨ 30ì˜ ê²Œì´íŠ¸ë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤.
        ë¶€íŠ¸ ìŠ¤íŠ¸ë© ë¶„ì„ì— ë”°ë¥´ë©´ ê²Œì´íŠ¸ê°€ ë ˆë²¨ 30ì—ìˆì„ ë•Œ 1ì¼ ìœ ì§€ìœ¨ì´ ë” ë†’ì„ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
        ê·¸ëŸ¬ë‚˜ í”Œë ˆì´ì–´ëŠ” í•˜ë£¨ ë™ì•ˆ ë§Œ ê²Œì„ì„í–ˆê¸° ë•Œë¬¸ì— ëŒ€ë¶€ë¶„ì˜ í”Œë ˆì´ì–´ê°€ ì•„ì§ ë ˆë²¨ 30ì— ë‹¤ë‹¤ë¥´ì§€ ì•Šì•˜ì„ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.
        ì¦‰, ëŒ€ë¶€ë¶„ì˜ ìœ ì €ë“¤ì€ ê²Œì´íŠ¸ê°€ 30ì— ìˆëŠ”ì§€ ì—¬ë¶€ì— ë”°ë¼ retentionì´ ì˜í–¥ë°›ì§€ ì•Šì•˜ì„ ê²ƒì…ë‹ˆë‹¤.
        ì¼ì£¼ì¼ ë™ì•ˆ í”Œë ˆì´ í•œ í›„ì—ëŠ” ë” ë§ì€ í”Œë ˆì´ì–´ê°€ ë ˆë²¨ 30ê³¼ 40ì— ë„ë‹¬í•˜ê¸° ë•Œë¬¸ì— 7 ì¼ retentionë„ í™•ì¸í•´ì•¼í•©ë‹ˆë‹¤.
    """

    df.groupby('version')['retention_7'].sum() / df.groupby('version')['retention_7'].count()

    boot_7d = []
    for i in range(500):
        boot_mean = df.sample(frac=1, replace=True).groupby('version')['retention_7'].mean()
        boot_7d.append(boot_mean)

    # listë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    boot_7d = pd.DataFrame(boot_7d)

    # ë‘ AB ê·¸ë£¹ê°„ì˜ % ì°¨ì´ í‰ê·  ì»¬ëŸ¼ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    boot_7d['diff'] = (boot_7d.gate_30 - boot_7d.gate_40) / boot_7d.gate_40 * 100

    # bootstrap % ì°¨ì´ë¥¼ ì‹œê°í™” í•©ë‹ˆë‹¤.
    ax = boot_7d['diff'].plot(kind='density')
    ax.set_title('% difference in 7-day retention between the two AB-groups')

    # ê²Œì´íŠ¸ê°€ ë ˆë²¨30ì— ìˆì„ ë•Œ 7-day retentionì´ ë” í´ í™•ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    print('ê²Œì´íŠ¸ê°€ ë ˆë²¨30ì— ìˆì„ ë•Œ 7-day retentionì´ í´ í™•ë¥ :', (boot_7d['diff'] > 0).mean())

    plt.show()

    print("\n", "=" * 3, "02.", "=" * 3)
    # T-test í†µê³„ì ì¸ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•˜ëŠ” ë°©ë²•.
    """
        https://www.statisticshowto.com/probability-and-statistics/t-test/
        T Score
            t-scoreê°€ í¬ë©´ ë‘ ê·¸ë£¹ì´ ë‹¤ë¥´ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
            t-scoreê°€ ì‘ìœ¼ë©´ ë‘ ê·¸ë£¹ì´ ë¹„ìŠ·í•˜ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
        P-values
            p-valueëŠ” 5%ìˆ˜ì¤€ì—ì„œ 0.05ì…ë‹ˆë‹¤.
            p-valuesëŠ” ì‘ì€ ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ì´ê²ƒì€ ë°ì´í„°ê°€ ìš°ì—°íˆ ë°œìƒí•œ ê²ƒì´ ì•„ë‹ˆë¼ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
            ì˜ˆë¥¼ ë“¤ì–´ p-valueê°€ 0.01 ì´ë¼ëŠ” ê²ƒì€ ê²°ê³¼ê°€ ìš°ì—°íˆ ë‚˜ì˜¬ í™•ë¥ ì´ 1%ì— ë¶ˆê³¼í•˜ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
            ëŒ€ë¶€ë¶„ì˜ ê²½ìš° 0.05 (5%) ìˆ˜ì¤€ì˜ p-valueë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ìŠµë‹ˆë‹¤. ì´ ê²½ìš° í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ë‹¤ê³  í•©ë‹ˆë‹¤.
            
        ìœ„ ë¶„ì„ê²°ê³¼ë¥¼ ë³´ë©´, ë‘ ê·¸ë£¹ì—ì„œ retention_1ì— ìˆì–´ì„œëŠ” ìœ ì˜í•˜ì§€ ì•Šê³ , retention_7ì—ì„œëŠ” ìœ ì˜ë¯¸í•œ ì°¨ì´ê°€ ìˆë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        ë‹¤ì‹œë§í•´, retention_7ì´ gate30ì´ gate40 ë³´ë‹¤ ë†’ì€ ê²ƒì€ ìš°ì—°íˆ ë°œìƒí•œ ì¼ì´ ì•„ë‹™ë‹ˆë‹¤.
        ì¦‰, gateëŠ” 30ì— ìˆëŠ” ê²ƒì´ 40ì— ìˆëŠ” ê²ƒë³´ë‹¤ retention 7 ì°¨ì›ì—ì„œ ë” ì¢‹ì€ ì„ íƒì§€ ì…ë‹ˆë‹¤.
    """


    # ìˆ˜í•™ì  ê³„ì‚°ì„ í•´ì£¼ëŠ” íŒŒì´ì¬ íŒ¨í‚¤ì§€
    from scipy import stats

    df_30 = df[df['version'] == 'gate_30']
    df_40 = df[df['version'] == 'gate_40']

    # ë…ë¦½í‘œë³¸ T-ê²€ì • (2 Sample T-Test)
    tTestResult = stats.ttest_ind(df_30['retention_1'], df_40['retention_1'])
    tTestResultDiffVar = stats.ttest_ind(df_30['retention_1'], df_40['retention_1'], equal_var=False)

    print(tTestResult, tTestResultDiffVar)

    tTestResult = stats.ttest_ind(df_30['retention_7'], df_40['retention_7'])
    tTestResultDiffVar = stats.ttest_ind(df_30['retention_7'], df_40['retention_7'], equal_var=False)
    print(tTestResult, tTestResultDiffVar)

    print("\n", "=" * 3, "03.", "=" * 3)

    # chi-square
    """
        chi-square
        ì‚¬ì‹¤ t-testëŠ” retention ì—¬ë¶€ë¥¼ 0,1 ë¡œ ë‘ê³  ë¶„ì„í•œ ê²ƒì…ë‹ˆë‹¤.
        í•˜ì§€ë§Œ ì‹¤ì œë¡œ retention ì—¬ë¶€ëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ì…ë‹ˆë‹¤. ì´ ë°©ë²•ë³´ë‹¤ëŠ” chi-squareê²€ì •ì„ í•˜ëŠ” ê²ƒì´ ë” ì¢‹ì€ ë°©ë²•ì…ë‹ˆë‹¤.
        ì¹´ì´ì œê³±ê²€ì •ì€ ì–´ë–¤ ë²”ì£¼í˜• í™•ë¥ ë³€ìˆ˜ ğ‘‹ ê°€ ë‹¤ë¥¸ ë²”ì£¼í˜• í™•ë¥ ë³€ìˆ˜ ğ‘Œ ì™€ ë…ë¦½ì¸ì§€ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§€ëŠ”ê°€ë¥¼ ê²€ì¦í•˜ëŠ”ë°ë„ ì‚¬ìš©ë©ë‹ˆë‹¤.
        ì¹´ì´ì œê³±ê²€ì •ì„ ë…ë¦½ì„ í™•ì¸í•˜ëŠ”ë° ì‚¬ìš©í•˜ë©´ ì¹´ì´ì œê³± ë…ë¦½ê²€ì •ì´ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.
        ë§Œì•½ ë‘ í™•ë¥ ë³€ìˆ˜ê°€ ë…ë¦½ì´ë¼ë©´ ğ‘‹=0 ì¼ ë•Œì˜ ğ‘Œ ë¶„í¬ì™€ ğ‘‹=1 ì¼ ë•Œì˜ ğ‘Œ ë¶„í¬ê°€ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤.
        ë‹¤ì‹œë§í•´ ë²„ì „ì´ 30ì¼ë•Œì™€ 40ì¼ ë•Œ ëª¨ë‘ Yì˜ ë¶„í¬ê°€ ê°™ì€ ê²ƒì…ë‹ˆë‹¤.
        ë”°ë¼ì„œ í‘œë³¸ ì§‘í•©ì´ ê°™ì€ í™•ë¥ ë¶„í¬ì—ì„œ ë‚˜ì™”ë‹¤ëŠ” ê²ƒì„ ê·€ë¬´ê°€ì„¤ë¡œ í•˜ëŠ” ì¹´ì´ì œê³±ê²€ì •ì„ í•˜ì—¬ ì±„íƒëœë‹¤ë©´ ë‘ í™•ë¥ ë³€ìˆ˜ëŠ” ë…ë¦½ì…ë‹ˆë‹¤.
        ë§Œì•½ ê¸°ê°ëœë‹¤ë©´ ë‘ í™•ë¥ ë³€ìˆ˜ëŠ” ìƒê´€ê´€ê³„ê°€ ìˆëŠ” ê²ƒì…ë‹ˆë‹¤.
        ë‹¤ì‹œë§í•´ ì¹´ì´ì œê³±ê²€ì • ê²°ê³¼ê°€ ê¸°ê°ëœë‹¤ë©´ ê²Œì´íŠ¸ê°€ 30ì¸ì§€ 40ì¸ì§€ ì—¬ë¶€ì— ë”°ë¼ retentionì˜ ê°’ì´ ë³€í™”í•˜ê²Œ ëœë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤.
        ğ‘‹ ì˜ ê°’ì— ë”°ë¥¸ ê°ê°ì˜ ğ‘Œ ë¶„í¬ê°€ 2ì°¨ì› í‘œ(contingency table)ì˜ í˜•íƒœë¡œ ì£¼ì–´ì§€ë©´ ë…ë¦½ì¸ ê²½ìš°ì˜ ë¶„í¬ì™€ ì‹¤ì œ y í‘œë³¸ë³¸í¬ì˜ ì°¨ì´ë¥¼ ê²€ì •í†µê³„ëŸ‰ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.
        ì´ ê°’ì´ ì¶©ë¶„íˆ í¬ë‹¤ë©´ ğ‘‹ ì™€ ğ‘Œ ëŠ” ìƒê´€ê´€ê³„ê°€ ìˆë‹¤.
    """
    # ë¶„í• í‘œë¥¼ ë§Œë“¤ê¸° ìœ„í•´ ë²„ì „ë³„ë¡œ ìƒì¡´ìì˜ ìˆ˜ í•©ê³„ë¥¼ êµ¬í•©ë‹ˆë‹¤.
    df.groupby('version').sum()

    # ë²„ì „ë³„ ì „ì²´ ìœ ì €ì˜ ìˆ˜ë¥¼ êµ¬í•©ë‹ˆë‹¤.
    df.groupby('version').count()

    import scipy as sp
    gate_40_01_sum = df.groupby('version').sum()['retention_1']['gate_40']
    gate_30_01_sum = df.groupby('version').sum()['retention_1']['gate_30']
    gate_40_07_sum = df.groupby('version').sum()['retention_7']['gate_40']
    gate_30_07_sum = df.groupby('version').sum()['retention_7']['gate_30']

    gate_40_01_cnt = df.groupby('version').count()['retention_1']['gate_40']
    gate_30_01_cnt = df.groupby('version').count()['retention_1']['gate_30']
    gate_40_07_cnt = df.groupby('version').count()['retention_7']['gate_40']
    gate_30_07_cnt = df.groupby('version').count()['retention_7']['gate_30']


    obs1 = np.array([[gate_40_01_sum, (gate_40_01_cnt - gate_40_01_sum)], [gate_30_01_sum, (gate_30_01_cnt - gate_30_01_sum)]])
    sp.stats.chi2_contingency(obs1)

    obs2 = np.array([[gate_40_07_sum, (gate_40_07_cnt - gate_40_07_sum)], [gate_30_07_sum, (gate_30_07_cnt - gate_30_07_sum)]])
    sp.stats.chi2_contingency(obs2)

    """
        OBS-1
        P-valueê°€ ì¤‘ìš” (0.075)
        (3.1698355431707994,
         0.07500999897705699,
         1,
         array([[20252.35970417, 25236.64029583],
                [19900.64029583, 24798.35970417]]))
        OBS-2
        P-valueê°€ ì¤‘ìš” (0.001)
        (9.915275528905669,
         0.0016391259678654423,
         1,
         array([[ 8463.49203885, 37025.50796115],
                [ 8316.50796115, 36382.49203885]]))
        ì¹´ì´ì œê³± ë…ë¦½ê²€ì •ì˜ ìœ ì˜í™•ë¥ ì€ 0.1%ì…ë‹ˆë‹¤.
        ì¦‰ ğ‘‹ ì™€ ğ‘Œ ëŠ” ìƒê´€ê´€ê³„ê°€ ìˆë‹¤ê³  ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        ê²Œì´íŠ¸ê°€ 30ì— ìˆëŠ”ì§€ 40ì— ìˆëŠ”ì§€ ì—¬ë¶€ì— ë”°ë¼ 7ì¼ ë’¤ retentionì´ ìƒê´€ê´€ê³„ê°€ ìˆëŠ” ê²ƒì…ë‹ˆë‹¤.
        7ì¼ ë’¤ retention ìœ ì§€ë¥¼ ìœ„í•˜ì—¬ ê²Œì´íŠ¸ëŠ” 30ì— ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.
    """

    """
        Bootstrap 
        T-Test  : í¬ê³  ì‘ì€ê²ƒì— ì˜ë¯¸ê°€ ìˆëŠ” ë°ì´í„°ì¼ ê²½ìš° ..? 
        Chai Square ë°ì´í„°ê°€ True Falseë¡œ ë‚˜ì˜¬ë•Œ..
        
        ê²°ë¡ 
            gateëŠ” 30ì— ìœ ì§€í•´ì•¼í•©ë‹ˆë‹¤.
            
            ë” ìƒê°í•´ ë³¼ ê²ƒ
            ì‹¤ì œë¡œëŠ” retention ì´ì™¸ì— í•¨ê»˜ ê³ ë ¤í•´ì•¼ í•  ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ë“¤ì´ ìˆìŠµë‹ˆë‹¤.
            ì•±ë‚´ êµ¬ë§¤, ê²Œì„ í”Œë ˆì´ íšŸìˆ˜, ì¹œêµ¬ì´ˆëŒ€ë¡œ ì¸í•œ referrer ë“± ì…ë‹ˆë‹¤.
            ë³¸ ë°ì´í„°ì—ì„œëŠ” retentionë§Œ ì£¼ì–´ì ¸ ìˆê¸°ì— í•œ ê°€ì§€ë¥¼ ì£¼ì•ˆì ì„ ë‘ì–´ ë¶„ì„ í–ˆìŠµë‹ˆë‹¤.
            ì„œë¹„ìŠ¤ ìš´ì˜ì, ê¸°íšì ì°¨ì›ì—ì„œ ì •ë§ ì¤‘ìš”í•œ ë©”íŠ¸ë¦­ì„ ì •í•˜ê³  ê·¸ ê²ƒì„ ê¸°ì¤€ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ í‰ê°€í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
    """


# marketing_02()


def marketing_03():
    """
        subject
            Machine_Running
        topic
            ex4. marketing_data
        content
            03. Revenue ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë‚˜ëˆ ë³´ì
        Describe
            ë¶„ì„í•  ë°ì´í„° íŒŒì•…
            mall ë°ì´í„° EDA
                CustomerID - ê³ ê°ë“¤ì—ê²Œ ë°°ì •ëœ ìœ ë‹ˆí¬í•œ ê³ ê° ë²ˆí˜¸ ì…ë‹ˆë‹¤.
                Gender - ê³ ê°ì˜ ì„±ë³„ ì…ë‹ˆë‹¤.
                Age - ê³ ê°ì˜ ë‚˜ì´ ì…ë‹ˆë‹¤.
                Annual Income (k$) - ê³ ê°ì˜ ì—°ì†Œë“ ì…ë‹ˆë‹¤.
                Spending Score (1-100) - ê³ ê°ì˜ êµ¬ë§¤í–‰ìœ„ì™€ êµ¬ë§¤ íŠ¹ì„±ì„ ë°”íƒ•ìœ¼ë¡œ mallì—ì„œ í• ë‹¹í•œ ê³ ê°ì˜ ì§€ë¶ˆ ì ìˆ˜ ì…ë‹ˆë‹¤.

            ë¬¸ì œ ì •ì˜
                ì „ì œ
                    ì£¼ì–´ì§„ ë°ì´í„°ê°€ ì ì ˆ ì •í™•í•˜ê²Œ ìˆ˜ì§‘, ê³„ì‚°ëœ ê²ƒì¸ì§€ì— ëŒ€í•œ ê²€ì¦ë¶€í„° ì‹œì‘í•´ì•¼í•˜ì§€ë§Œ,
                    ì§€ê¸ˆì€ ì£¼ì–´ì§„ ë°ì´í„°ê°€ ì •í™•í•˜ë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
                    (ì˜ˆ: Spending ScoreëŠ” ì ì ˆí•˜ê²Œ ì‚°ì¶œëœ ê²ƒì´ë¼ í™•ì‹ í•˜ê³  ì‹œì‘í•©ë‹ˆë‹¤)
                    ì£¼ì–´ì§„ ë³€ìˆ˜ë“¤ì„ ê°€ì§€ê³  ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.
                    ê°€ì¥ ì ì ˆí•œ ìˆ˜ì˜ ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.
                ë¶„ì„ì˜ ëª©ì 
                    ê° ì„¸ê·¸ë¨¼íŠ¸ ë³„ íŠ¹ì„±ì„ ë„ì¶œí•©ë‹ˆë‹¤.
                    ê° ì„¸ê·¸ë¨¼íŠ¸ë³„ íŠ¹ì„±ì— ë§ëŠ” í™œìš©ë°©ì•ˆ, ì „ëµì„ ê³ ë¯¼í•´ë´…ë‹ˆë‹¤.
        sub Contents
            01.
    """

    df = pd.read_csv("./data_file/Mall_Customers.csv")
    fig, axes = plt.subplots(2, 4, sharey=False, tight_layout=True, figsize=(15, 6), num='mobile game')

    # ë°ì´í„° í™•ì¸
    print(df.shape)
    print(df.tail())

    # ê²°ì¸¡ê°’ ì¸¡ì •
    print(df.info())
    print(df.isnull().sum())

    # ê¸°ìˆ í†µê³„ í™•ì¸ : df.describe()
    print(df.describe())

    # ë³€ìˆ˜ê°„ì˜ correlation í™•ì¸ df.corr() ì‹œê°í™”
    def open_data_graph():
        corr = df.corr()
        print(corr)

        ax_temp = axes[0, 0]
        ax_temp.set_title('HeatMap')
        sns.heatmap(corr, annot=True, ax=ax_temp)

        # pairplot ì‹œê°í™” ìƒì„±
        print(df.columns)

        ax_temp = axes[0, 1]
        ax_temp.set_title('Age dist plot')
        sns.distplot(df['Age'], ax=ax_temp)

        ax_temp = axes[0, 2]
        ax_temp.set_title('Annual Income (k$) dist plot')
        sns.distplot(df['Age'], ax=ax_temp)

        ax_temp = axes[0, 3]
        ax_temp.set_title('Spending Score (1-100) dist plot')
        sns.distplot(df['Spending Score (1-100)'], ax=ax_temp)

        ax_temp = axes[1, 0]
        ax_temp.set_title('Genter Count plot')
        sns.countplot(df['Gender'], ax=ax_temp)

        ax_temp = axes[1, 1]
        ax_temp.set_title('boxplot plot')
        sns.boxplot(data=df, x='Gender', y='Age', hue='Gender', palette=['m', 'g'], ax=ax_temp)


        # ì„œë¸Œí”Œë¡¯ì— ì•ˆë“¤ì–´ê°€ëŠ” ê²ƒë“¤
        sns.pairplot(df[['CustomerID', 'Gender', 'Age', 'Annual Income (k$)', 'Spending Score (1-100)']])
        sns.pairplot(df[['CustomerID', 'Gender', 'Age', 'Annual Income (k$)', 'Spending Score (1-100)']], hue='Gender')
        # lmplotì€ regplotì„ ì„œë¸Œ í”Œë¡¯ìœ¼ë¡œ í•˜ëŠ” í”Œë¡¯ì…ë‹ˆë‹¤
        sns.lmplot(data=df, x='Age', y='Annual Income (k$)', hue='Gender', fit_reg=False)
        sns.lmplot(data=df, x='Spending Score (1-100)', y='Annual Income (k$)', hue='Gender', fit_reg=False)

        plt.show()

    # open_data_graph()


    print("\n", "=" * 5, "03", "=" * 5)

    print("\n", "=" * 3, "01.", "=" * 3)
    """
        ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ í´ëŸ¬ìŠ¤í„°ë§
        K-meansë¥¼ ì‚¬ìš©í•œ í´ëŸ¬ìŠ¤í„°ë§
            K-meansëŠ” ê°€ì¥ ë¹ ë¥´ê³  ë‹¨ìˆœí•œ í´ëŸ¬ìŠ¤í„°ë§ ë°©ë²• ì¤‘ í•œ ê°€ì§€ ì…ë‹ˆë‹¤.
            scikit-learnì˜ cluster ì„œë¸ŒíŒ¨í‚¤ì§€ KMeans í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html
        
            n_clusters: êµ°ì§‘ì˜ ê°¯ìˆ˜ (default=8)
            init: ì´ˆê¸°í™” ë°©ë²•. "random"ì´ë©´ ë¬´ì‘ìœ„, "k-means++"ì´ë©´ K-í‰ê· ++ ë°©ë²•.(default=k-means++)
            n_init: centroid seed ì‹œë„ íšŸìˆ˜. ë¬´ì‘ìœ„ ì¤‘ì‹¬ìœ„ì¹˜ ëª©ë¡ ì¤‘ ê°€ì¥ ì¢‹ì€ ê°’ì„ ì„ íƒí•œë‹¤.(default=10)
            max_iter: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜.(default=300)
            random_state: ì‹œë“œê°’.(default=None)     
        
        2ê°€ì§€ ë³€ìˆ˜ê°€ ì•„ë‹Œ ì—¬ëŸ¬ê°€ì§€ ë³€ìˆ˜ë¥¼ í™œìš©í•œí›„ ì°¨ì› ì¶•ì†Œë¥¼ í†µí•´ì„œ êµ°ì§‘í™” í•œë‹¤.
    """
    ### Age & spending Score ë‘ ê°€ì§€ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•œ í´ëŸ¬ìŠ¤í„°ë§
    # ['CustomerID', 'Gender', 'Age', 'Annual Income (k$)', 'Spending Score (1-100)']


    from sklearn.cluster import KMeans
    # X1ì— 'Age' , 'Spending Score (1-100)'ì˜ ê°’ì„ ë„£ì–´ì¤ë‹ˆë‹¤.
    x1 = df[['Age', 'Spending Score (1-100)']].values
    print(x1.shape)

    # inertia ë¼ëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.
    inertia = []

    # êµ°ì§‘ìˆ˜ nì„ 1ì—ì„œ 20ê¹Œì§€ ëŒì•„ê°€ë©° X1ì— ëŒ€í•´ k-means++ ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•˜ì—¬ inertiaë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥í•©ë‹ˆë‹¤.
    for n in range(1, 20):
        algorithm = (KMeans(n_clusters=n, random_state=30))
        algorithm.fit(x1)
        inertia.append(algorithm.inertia_)

    """
        Inertia valueë¥¼ ì´ìš©í•œ ì ì • k ì„ íƒ
        ê´€ì„±(Inertia)ì— ê¸°ë°˜í•˜ì—¬ n ê°œìˆ˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
        ê´€ì„±(Inertia) : ê° ì¤‘ì‹¬ì (centroid)ì—ì„œ êµ°ì§‘ ë‚´ ë°ì´í„°ê°„ì˜ ê±°ë¦¬ë¥¼ í•©ì‚°í•œ ê²ƒìœ¼ë¡œ êµ°ì§‘ì˜ ì‘ì§‘ë„ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. 
        ì´ ê°’ì´ ì‘ì„ìˆ˜ë¡ ì‘ì§‘ë„ ë†’ì€ êµ°ì§‘í™” ì…ë‹ˆë‹¤. ì¦‰, ì‘ì„ ìˆ˜ë¡ ì¢‹ì€ ê°’ ì…ë‹ˆë‹¤.
        https://scikit-learn.org/stable/modules/clustering.html
    """


    print(inertia)
    axes[0, 0].plot(np.arange(1, 20), inertia, 'o')
    axes[0, 0].plot(np.arange(1, 20), inertia, '-', alpha=0.8)
    axes[0, 0].set_title('KMeans small is best')
    axes[0, 0].set_xlabel('Number of Clusters')
    axes[0,0].set_ylabel('Inertia')
    plt.show()

    # ê¸‰ê²©í•˜ê²Œ ë³€í•˜ëŠ” ì§€ì ì´ êµ°ì§‘ìœ¼ë¡œ ì¡ê¸°ì— ì¢‹ë‹¤.
    # êµ°ì§‘ìˆ˜ë¥¼ 4ë¡œ ì§€ì •í•˜ì—¬ ì‹œê°í™” í•´ë´…ë‹ˆë‹¤.
    algorithm = (KMeans(n_clusters=4, init='k-means++', n_init=10, max_iter=300,
                        tol=0.0001, random_state=111, algorithm='elkan'))
    algorithm.fit(x1)
    labels1 = algorithm.labels_
    centroids1 = algorithm.cluster_centers_

    h = 0.02
    x_min, x_max = x1[:, 0].min() - 1, x1[:, 0].max() + 1
    y_min, y_max = x1[:, 1].min() - 1, x1[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
    Z = algorithm.predict(np.c_[xx.ravel(), yy.ravel()])

    plt.figure(1, figsize=(15, 7))
    plt.clf()
    Z = Z.reshape(xx.shape)
    plt.imshow(Z, interpolation='nearest',
               extent=(xx.min(), xx.max(), yy.min(), yy.max()),
               cmap=plt.cm.Pastel2, aspect='auto', origin='lower')

    plt.scatter(x='Age', y='Spending Score (1-100)', data=df, c=labels1,
                s=200)
    plt.scatter(x=centroids1[:, 0], y=centroids1[:, 1], s=300, c='red', alpha=0.5)
    plt.ylabel('Spending Score (1-100)'), plt.xlabel('Age')
    plt.show()

    """
        ì—°ë ¹-ì†Œë¹„ì ìˆ˜ë¥¼ í™œìš©í•œ êµ°ì§‘ 4ê°œëŠ” ì•„ë˜ì™€ ê°™ì´ ëª…ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

        ì €ì—°ë ¹-ê³ ì†Œë¹„ êµ°
        ì €ì—°ë ¹-ì¤‘ì†Œë¹„ êµ°
        ê³ ì—°ë ¹-ì¤‘ì†Œë¹„ êµ°
        ì €ì†Œë¹„ êµ°
        êµ°ì§‘ë³„ í™œìš© ì „ëµ ì˜ˆì‹œ
            ì´ ìˆ˜í¼ë§ˆì¼“ mallì˜ ê²½ìš° ì†Œë¹„ì ìˆ˜ê°€ ë†’ì€ ê³ ê°ë“¤ì€ ëª¨ë‘ 40ì„¸ ì´í•˜ì˜ ì Šì€ ê³ ê°ì…ë‹ˆë‹¤.
            ì†Œë¹„ì ìˆ˜ê°€ ë†’ì€ ê³ ê°ë“¤ì€ ì—°ë ¹ëŒ€ê°€ ë¹„ìŠ·í•œ ë§Œí¼ ë¹„ìŠ·í•œ êµ¬ë§¤íŒ¨í„´ê³¼ ì·¨í–¥ì„ ê°€ì§ˆ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
            í•´ë‹¹ êµ°ì§‘ì˜ ì†Œë¹„ì íŠ¹ì„±ì„ ë” ë¶„ì„í•´ë³¸ ë’¤ í•´ë‹¹ êµ°ì§‘ì˜ ì†Œë¹„ì ëŒ€ìƒ VIP ì „ëµì„ ìˆ˜ë¦½í•´ë´…ë‹ˆë‹¤.
            ì†Œë¹„ì ìˆ˜ê°€ ì¤‘ê°„ì •ë„ì¸ ê³ ê°ë“¤ì—ê²ŒëŠ” ì—°ë ¹ì— ë”°ë¼ ë‘ ê°œ ì§‘ë‹¨ìœ¼ë¡œ ë‚˜ëˆ ì„œ ì ‘ê·¼í•´ë´…ë‹ˆë‹¤.
            ì†Œë¹„ì ìˆ˜ê°€ ë‚®ì€ ê³ ê°êµ°ì€ ì—°ë ¹ëŒ€ë³„ë¡œ ì¤‘ì†Œë¹„ì ìˆ˜ êµ°ì§‘ì— í¸ì…ë  ìˆ˜ ìˆë„ë¡ ì ‘ê·¼í•´ë´…ë‹ˆë‹¤.
    """

    print("\n", "=" * 3, "02.", "=" * 3)
    # X1ì— 'Annual Income (k$)' , 'Spending Score (1-100)' ì˜ ê°’ì„ ë„£ì–´ì¤ë‹ˆë‹¤.
    X2 = df[['Annual Income (k$)', 'Spending Score (1-100)']].values

    # inertia ë¼ëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.
    inertia = []

    # êµ°ì§‘ìˆ˜ nì„ 1ì—ì„œ 11ê¹Œì§€ ëŒì•„ê°€ë©° X1ì— ëŒ€í•´ k-means++ ì•Œê³ ë¦¬ì¦˜ì„ ì ìš©í•˜ì—¬ inertiaë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥í•©ë‹ˆë‹¤.
    for n in range(1, 11):
        algorithm = (KMeans(n_clusters=n))
        algorithm.fit(X2)
        inertia.append(algorithm.inertia_)

    plt.figure(1, figsize=(16, 5))
    plt.plot(np.arange(1, 11), inertia, 'o')
    plt.plot(np.arange(1, 11), inertia, '-', alpha=0.8)
    plt.xlabel('Number of Clusters'), plt.ylabel('Inertia')
    plt.show()

    # êµ°ì§‘ìˆ˜ë¥¼ 5ë¡œ ì§€ì •í•˜ì—¬ ì‹œê°í™” í•´ë´…ë‹ˆë‹¤.
    algorithm = (KMeans(n_clusters=5, init='k-means++', n_init=10, max_iter=300,
                        tol=0.0001, random_state=111, algorithm='elkan'))
    algorithm.fit(X2)
    labels2 = algorithm.labels_
    centroids2 = algorithm.cluster_centers_

    h = 0.02
    x_min, x_max = X2[:, 0].min() - 1, X2[:, 0].max() + 1
    y_min, y_max = X2[:, 1].min() - 1, X2[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
    Z2 = algorithm.predict(np.c_[xx.ravel(), yy.ravel()])

    plt.figure(1, figsize=(15, 7))
    plt.clf()
    Z2 = Z2.reshape(xx.shape)
    plt.imshow(Z2, interpolation='nearest',
               extent=(xx.min(), xx.max(), yy.min(), yy.max()),
               cmap=plt.cm.Pastel2, aspect='auto', origin='lower')

    plt.scatter(x='Annual Income (k$)', y='Spending Score (1-100)', data=df, c=labels2, s=200)
    plt.scatter(x=centroids2[:, 0], y=centroids2[:, 1], s=300, c='red', alpha=0.5)
    plt.ylabel('Spending Score (1-100)'), plt.xlabel('Annual Income (k$)')
    plt.show()

    print("\n", "=" * 3, "03.", "=" * 3)

    """
        ë¶„ì„ ëª¨ë¸ë§ / ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ í•´ì„.
        ì‹¤ë£¨ì—£ ìŠ¤ì½”ì–´ë¥¼ ì‚¬ìš©í•œ k ì„ íƒ
        ê°€ì¥ ì¢‹ì€ ê°’ì€ 1ì´ê³  ìµœì•…ì˜ ê°’ì€ -1
       
            Silhouette CoefficientëŠ” ê° ìƒ˜í”Œì˜ í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ ê±°ë¦¬ì˜ í‰ê·  (a)ì™€ ì¸ì ‘ í´ëŸ¬ìŠ¤í„°ì™€ì˜ ê±°ë¦¬ í‰ê·  (b)ì„ ì‚¬ìš©í•˜ì—¬ ê³„ì‚°í•©ë‹ˆë‹¤.
            í•œ ìƒ˜í”Œì˜ Silhouette CoefficientëŠ” (b - a) / max(a, b)ì…ë‹ˆë‹¤.
            
            0 ê·¼ì²˜ì˜ ê°’ì€ í´ëŸ¬ìŠ¤í„°ê°€ ì˜¤ë²„ë©ë˜ì—ˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤
            ìŒìˆ˜ ê°’ì€ ìƒ˜í”Œì´ ì˜ëª»ëœ í´ëŸ¬ìŠ¤í„°ì— ë°°ì •ë˜ì—ˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„°ê°€ ë” ìœ ì‚¬í•œ êµ°ì§‘ì´ë¼ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.
            https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html
    """
    from sklearn.cluster import KMeans
    from sklearn.metrics import silhouette_samples, silhouette_score
    import matplotlib.cm as cm

    # í´ëŸ¬ìŠ¤í„°ì˜ ê°¯ìˆ˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.
    range_n_clusters = [6]

    # ì‚¬ìš©í•  ì»¬ëŸ¼ ê°’ì„ ì§€ì •í•´ì¤ë‹ˆë‹¤.
    X = df[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']].values

    for n_clusters in range_n_clusters:
        # 1 X 2 ì˜ ì„œë¸Œí”Œë¡¯ì„ ë§Œë“­ë‹ˆë‹¤.
        fig, (ax1, ax2) = plt.subplots(1, 2)
        fig.set_size_inches(18, 7)

        # ì²« ë²ˆì§¸ ì„œë¸Œí”Œë¡¯ì€ ì‹¤ë£¨ì—£ í”Œë¡¯ì…ë‹ˆë‹¤.
        # silhouette coefficientëŠ” -1ì—ì„œ 1 ì‚¬ì´ì˜ ê°’ì„ ê°€ì§‘ë‹ˆë‹¤.
        # í•˜ì§€ë§Œ ì‹œê°í™”ì—ì„œëŠ” -0.1ì—ì„œ 1ì‚¬ì´ë¡œ ì§€ì •í•´ì¤ë‹ˆë‹¤.
        ax1.set_xlim([-0.1, 1])

        # clustererë¥¼ n_clusters ê°’ìœ¼ë¡œ ì´ˆê¸°í™” í•´ì¤ë‹ˆë‹¤.
        # ì¬í˜„ì„±ì„ ìœ„í•´ random seedë¥¼ 10ìœ¼ë¡œ ì§€ì • í•©ë‹ˆë‹¤.
        clusterer = KMeans(n_clusters=n_clusters, random_state=10)
        cluster_labels = clusterer.fit_predict(X)

        # silhouette_scoreëŠ” ëª¨ë“  ìƒ˜í”Œì— ëŒ€í•œ í‰ê· ê°’ì„ ì œê³µí•©ë‹ˆë‹¤.
        # ì‹¤ë£¨ì—£ ìŠ¤ì½”ì–´ëŠ” í˜•ì„±ëœ êµ°ì§‘ì— ëŒ€í•´ ë°€ë„(density)ì™€ ë¶„ë¦¬(seperation)ì— ëŒ€í•´ ê²¬í•´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
        silhouette_avg = silhouette_score(X, cluster_labels)
        print("For n_clusters =", n_clusters,
              "The average silhouette_score is :", silhouette_avg)

        # ê° ìƒ˜í”Œì— ëŒ€í•œ ì‹¤ë£¨ì—£ ìŠ¤ì½”ì–´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        sample_silhouette_values = silhouette_samples(X, cluster_labels)

        y_lower = 10
        for i in range(n_clusters):
            # í´ëŸ¬ìŠ¤í„° iì— ì†í•œ ìƒ˜í”Œë“¤ì˜ ì‹¤ë£¨ì—£ ìŠ¤ì½”ì–´ë¥¼ ì·¨í•©í•˜ì—¬ ì •ë ¬í•©ë‹ˆë‹¤.
            ith_cluster_silhouette_values = \
                sample_silhouette_values[cluster_labels == i]

            ith_cluster_silhouette_values.sort()

            size_cluster_i = ith_cluster_silhouette_values.shape[0]
            y_upper = y_lower + size_cluster_i

            color = cm.nipy_spectral(float(i) / n_clusters)
            ax1.fill_betweenx(np.arange(y_lower, y_upper),
                              0, ith_cluster_silhouette_values,
                              facecolor=color, edgecolor=color, alpha=0.7)

            # ê° í´ëŸ¬ìŠ¤í„°ì˜ ì´ë¦„ì„ ë‹¬ì•„ì„œ ì‹¤ë£¨ì—£ í”Œë¡¯ì˜ Labelì„ ì§€ì •í•´ì¤ë‹ˆë‹¤.
            ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))

            # ë‹¤ìŒ í”Œë¡¯ì„ ìœ„í•œ ìƒˆë¡œìš´ y_lowerë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
            y_lower = y_upper + 10  # 10 for the 0 samples

        ax1.set_title("The silhouette plot for the various clusters.")
        ax1.set_xlabel("The silhouette coefficient values")
        ax1.set_ylabel("Cluster label")

        # ëª¨ë“  ê°’ì— ëŒ€í•œ ì‹¤ë£¨ì—£ ìŠ¤ì½”ì–´ì˜ í‰ê· ì„ ìˆ˜ì§ì„ ìœ¼ë¡œ ê·¸ë ¤ì¤ë‹ˆë‹¤.
        ax1.axvline(x=silhouette_avg, color="red", linestyle="--")

        ax1.set_yticks([])  # yaxis labels / ticks ë¥¼ ì§€ì›Œì¤ë‹ˆë‹¤.
        ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])

        # ë‘ ë²ˆì§¸ í”Œë¡¯ì´ ì‹¤ì œ í´ëŸ¬ìŠ¤í„°ê°€ ì–´ë–»ê²Œ í˜•ì„±ë˜ì—ˆëŠ”ì§€ ì‹œê°í™” í•©ë‹ˆë‹¤.
        colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)
        ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,
                    c=colors, edgecolor='k')

        # í´ëŸ¬ìŠ¤í„°ì˜ ì´ë¦„ì„ ì§€ì–´ì¤ë‹ˆë‹¤.
        centers = clusterer.cluster_centers_
        # í´ëŸ¬ìŠ¤í„°ì˜ ì¤‘ì•™ì— í•˜ì–€ ë™ê·¸ë¼ë¯¸ë¥¼ ê·¸ë ¤ì¤ë‹ˆë‹¤.
        ax2.scatter(centers[:, 0], centers[:, 1], marker='o',
                    c="white", alpha=1, s=200, edgecolor='k')

        for i, c in enumerate(centers):
            ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,
                        s=50, edgecolor='k')

        ax2.set_title("The visualization of the clustered data.")
        ax2.set_xlabel("Feature space for the 1st feature")
        ax2.set_ylabel("Feature space for the 2nd feature")

        plt.suptitle(("Silhouette analysis for KMeans clustering on sample data "
                      "with n_clusters = %d" % n_clusters),
                     fontsize=14, fontweight='bold')

    plt.show()

    print(n_clusters, cluster_labels, cluster_labels.shape)
    df['cluster'] = cluster_labels
    print(df.groupby('cluster')['Age'].mean())
    sns.boxplot(x='cluster', y="Age", hue="Gender", palette=["c", "m"], data=df)
    """
        boxplotì€ ì¤‘ì•™ê°’, í‘œì¤€ í¸ì°¨ ë“±, ë¶„í¬ì˜ ê°„ëµí•œ íŠ¹ì„±ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
        ê° ì¹´í…Œê³ ë¦¬ ê°’ì— ë”°ë¥¸ ë¶„í¬ì˜ ì‹¤ì œ ë°ì´í„°ì™€ í˜•ìƒì„ ë³´ê³  ì‹¶ë‹¤ë©´ violinplot, stripplot, swarmplot ë“±ìœ¼ë¡œ ì‹œê°í™” í•´ë´…ë‹ˆë‹¤.
        violinplotì€ ì„¸ë¡œ ë°©í–¥ìœ¼ë¡œ ì»¤ë„ ë°€ë„ íˆìŠ¤í† ê·¸ë¨ì„ ê·¸ë ¤ì¤ë‹ˆë‹¤. ì–‘ìª½ì´ ì™¼ìª½, ì˜¤ë¥¸ìª½ ëŒ€ì¹­ì´ ë˜ë„ë¡ í•˜ì—¬ ë°”ì´ì˜¬ë¦°ì²˜ëŸ¼ ë³´ì…ë‹ˆë‹¤.
        violinplot: http://seaborn.pydata.org/generated/seaborn.violinplot.html
        swarmplotì€ stripplotê³¼ ìœ ì‚¬í•˜ë©° ë°ì´í„°ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì ì´ ê²¹ì¹˜ì§€ ì•Šë„ë¡ ì˜†ìœ¼ë¡œ ì´ë™í•´ì„œ ê·¸ë ¤ì¤ë‹ˆë‹¤.
        swarmplot: http://seaborn.pydata.org/generated/seaborn.swarmplot.html
    """

    df['cluster'] = cluster_labels
    print(df.tail())

    # ê° ê·¸ë£¹ì˜ íŠ¹ì„±ì„ í™•ì¸í•˜ê¸°
    print(df.groupby('cluster')['Age'].mean())

    fig, axes = plt.subplots(2, 2, sharey=False, tight_layout=True, figsize=(15, 6), num='mobile game')
    # violinplot
    sns.violinplot(x='cluster', y='Annual Income (k$)', data=df, inner=None, ax=axes[0, 0])
    sns.swarmplot(x='cluster', y="Annual Income (k$)", data=df, ax=axes[0, 0], color='white', edgecolor='gray')
    sns.boxplot(x='cluster', y="Annual Income (k$)", data=df, ax=axes[0, 1])

    sns.violinplot(x='cluster', y='Spending Score (1-100)', data=df, inner=None, ax=axes[1, 0])
    sns.swarmplot(x='cluster', y="Spending Score (1-100)", data=df, ax=axes[1, 0], color='white', edgecolor='gray')

    sns.violinplot(x='cluster', y='Age', data=df, inner=None, ax=axes[1, 1])
    sns.swarmplot(x='cluster', y="Age", data=df, ax=axes[1, 1], color='white', edgecolor='gray')
    plt.show()

    # 3ê°œì˜ ì‹œê°í™”ë¥¼ í•œ í™”ë©´ì— ë°°ì¹˜í•©ë‹ˆë‹¤.
    figure, ((ax1, ax2, ax3)) = plt.subplots(nrows=1, ncols=3)

    # ì‹œê°í™”ì˜ ì‚¬ì´ì¦ˆë¥¼ ì„¤ì •í•´ì¤ë‹ˆë‹¤.
    figure.set_size_inches(20, 6)
    # í´ëŸ¬ìŠ¤í„°ë³„ë¡œ swarmplotì„ ì‹œê°í™”í•´ë´…ë‹ˆë‹¤.
    ax1 = sns.violinplot(x="cluster", y='Annual Income (k$)', data=df, inner=None, ax=ax1)
    ax1 = sns.swarmplot(x="cluster", y='Annual Income (k$)', data=df,
                        color="white", edgecolor="gray", ax=ax1)

    ax2 = sns.violinplot(x="cluster", y='Spending Score (1-100)', data=df, inner=None, ax=ax2)
    ax2 = sns.swarmplot(x="cluster", y='Spending Score (1-100)', data=df,
                        color="white", edgecolor="gray", ax=ax2)

    ax3 = sns.violinplot(x="cluster", y='Age', data=df, inner=None, ax=ax3)
    ax3 = sns.swarmplot(x="cluster", y='Age', data=df,
                        color="white", edgecolor="gray", ax=ax3, hue="Gender")
    plt.show()
    """
       
        ì¶”ê°€ ë¶„ì„ì„ í•´ë³¸ë‹¤ë©´
        "Gender" ë³€ìˆ˜ í™œìš©
        K-meansëŠ” ê¸°ë³¸ì ìœ¼ë¡œ numerical variableì„ ì‚¬ìš©í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤. ìœ í´ë¦¬ë””ì•ˆ ê±°ë¦¬ë¥¼ ê³„ì‚°í•´ì•¼í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
        Gender ë³€ìˆ˜ë¥¼ one-hot-encodingí•˜ì—¬ ìˆ«ìë¡œ ë°”ê¿”ì¤€ ë’¤ ë³€ìˆ˜ë¡œ ì¶”ê°€í•˜ì—¬ í™œìš©í•´ë´…ë‹ˆë‹¤.
        
        ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜ê°€ ëŒ€ë¶€ë¶„ì¸ ê²½ìš°ì˜ êµ°ì§‘í™”
        k-modes ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        https://pypi.org/project/kmodes/
        
    """


marketing_03()

def marketing_temp():
    """
        subject
            Machine_Running
        topic
            ex4. marketing_data
        content
            temp
        Describe

        sub Contents
            01.
    """

    print("\n", "=" * 5, "temp", "=" * 5)
    print("\n", "=" * 3, "01.", "=" * 3)
    print("\n", "=" * 3, "02.", "=" * 3)
    print("\n", "=" * 3, "03.", "=" * 3)

# marketing_temp()

